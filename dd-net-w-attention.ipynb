{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn6uaZYCINDy"
      },
      "source": [
        "! pip install -q keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBLSQB8bRtdT"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import scipy.ndimage.interpolation as inter\n",
        "from scipy.signal import medfilt\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras import layers\n",
        "from tensorflow.keras.callbacks import *\n",
        "from keras import backend as K\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import google.colab.files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Dd8w2Uaks3"
      },
      "source": [
        "1. Define configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyxDYnOJaotB"
      },
      "source": [
        "random.seed(1234)\n",
        "\n",
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.frame_l = 32 # the length of frames\n",
        "        self.joint_n = 12 # the number of joints\n",
        "        self.joint_n = 22 # the number of joints\n",
        "        self.joint_d = 3 # the dimension of joints\n",
        "        self.clc_coarse = 14 # the number of coarse class\n",
        "        self.clc_fine = 28 # the number of fine-grained class\n",
        "        self.feat_d = 231\n",
        "        self.filters = 64\n",
        "C = Config()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KG-n2OiaF4h"
      },
      "source": [
        "2. Define data processing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gToZ5f6haNKs"
      },
      "source": [
        "# Temple resizing function\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import scipy.ndimage.interpolation as inter\n",
        "from scipy.signal import medfilt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "###################################################################################\n",
        "\n",
        "\n",
        "#Rescale to be 64 frames\n",
        "def zoom(p,target_l=64,joints_num=25,joints_dim=3):\n",
        "    l = p.shape[0]\n",
        "    p_new = np.empty([target_l,joints_num,joints_dim])\n",
        "    for m in range(joints_num):\n",
        "        for n in range(joints_dim):\n",
        "            p[:,m,n] = medfilt(p[:,m,n],3)\n",
        "            p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]\n",
        "    return p_new\n",
        "\n",
        "def sampling_frame(p,C):\n",
        "    full_l = p.shape[0] # full length\n",
        "    if random.uniform(0,1)<0.5: # aligment sampling\n",
        "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
        "        s = random.randint(0, full_l-int(valid_l))\n",
        "        e = s+valid_l # sample end point\n",
        "        p = p[int(s):int(e),:,:]\n",
        "    else: # without aligment sampling\n",
        "        valid_l = np.round(np.random.uniform(0.9,1)*full_l)\n",
        "        index = np.sort(np.random.choice(range(0,full_l),int(valid_l),replace=False))\n",
        "        p = p[index,:,:]\n",
        "    p = zoom(p,C.frame_l,C.joint_n,C.joint_d)\n",
        "    return p\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "def get_CG(p,C):\n",
        "    M = []\n",
        "    iu = np.triu_indices(C.joint_n,1,C.joint_n)\n",
        "    for f in range(C.frame_l):\n",
        "        #distance max\n",
        "        d_m = cdist(p[f],np.concatenate([p[f],np.zeros([1,C.joint_d])]),'euclidean')\n",
        "        d_m = d_m[iu]\n",
        "        M.append(d_m)\n",
        "    M = np.stack(M)\n",
        "    return M\n",
        "\n",
        "def normlize_range(p):\n",
        "    # normolize to start point, use the center for hand case\n",
        "    p[:,:,0] = p[:,:,0]-np.mean(p[:,:,0])\n",
        "    p[:,:,1] = p[:,:,1]-np.mean(p[:,:,1])\n",
        "    p[:,:,2] = p[:,:,2]-np.mean(p[:,:,2])\n",
        "    return p\n",
        "\n",
        "def cm_analysis(y_true, y_pred, filename, labels, ymap=None, figsize=(8,8)):\n",
        "    \"\"\"\n",
        "    Generate matrix plot of confusion matrix with pretty annotations.\n",
        "    The plot image is saved to disk.\n",
        "    args:\n",
        "      y_true:    true label of the data, with shape (nsamples,)\n",
        "      y_pred:    prediction of the data, with shape (nsamples,)\n",
        "      filename:  filename of figure file to save\n",
        "      labels:    string array, name the order of class labels in the confusion matrix.\n",
        "                 use `clf.classes_` if using scikit-learn models.\n",
        "                 with shape (nclass,).\n",
        "      ymap:      dict: any -> string, length == nclass.\n",
        "                 if not None, map the labels & ys to more understandable strings.\n",
        "                 Caution: original y_true, y_pred and labels must align.\n",
        "      figsize:   the size of the figure plotted.\n",
        "    \"\"\"\n",
        "    if ymap is not None:\n",
        "        y_pred = [ymap[yi] for yi in y_pred]\n",
        "        y_true = [ymap[yi] for yi in y_true]\n",
        "        labels = [ymap[yi] for yi in labels]\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "    cm_perc = cm / cm_sum.astype(float) * 100\n",
        "    annot = np.empty_like(cm).astype(str)\n",
        "    nrows, ncols = cm.shape\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            c = cm[i, j]\n",
        "            p = cm_perc[i, j]\n",
        "            if i == j:\n",
        "                s = cm_sum[i]\n",
        "                #annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "                annot[i, j] = '%.1f' % (p)\n",
        "            elif c == 0:\n",
        "                annot[i, j] = ''\n",
        "            else:\n",
        "                #annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "                annot[i, j] = '%.1f' % (p)\n",
        "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    cm.index.name = 'Actual'\n",
        "    cm.columns.name = 'Predicted'\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(cm, annot=annot, fmt='', ax=ax, cbar=False, cmap=\"YlGnBu\")\n",
        "    plt.savefig(filename)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDzVwCSYv6bS"
      },
      "source": [
        "3. Define network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVHcN8sGav6m"
      },
      "source": [
        "\n",
        "def poses_diff(x):\n",
        "    H, W = x.get_shape()[1],x.get_shape()[2]\n",
        "    x = tf.subtract(x[:,1:,...],x[:,:-1,...])\n",
        "    x = tf.image.resize(x,size=[H,W])\n",
        "    return x\n",
        "\n",
        "def pose_motion(P,frame_l):\n",
        "    P_diff_slow = Lambda(lambda x: poses_diff(x))(P)\n",
        "    P_diff_slow = Reshape((frame_l,-1))(P_diff_slow)\n",
        "    P_fast = Lambda(lambda x: x[:,::2,...])(P)\n",
        "    P_diff_fast = Lambda(lambda x: poses_diff(x))(P_fast)\n",
        "    P_diff_fast = Reshape((int(frame_l/2),-1))(P_diff_fast)\n",
        "\n",
        "    print(P_diff_slow.shape, P_diff_fast.shape)\n",
        "    return P_diff_slow, P_diff_fast\n",
        "\n",
        "\n",
        "\n",
        "def spatial_attention_layer(input_feature):\n",
        "    kernel_size = 3\n",
        "    avg_pool = Lambda(lambda x: K.mean(x, axis=-1, keepdims=True))(input_feature)\n",
        "    max_pool = Lambda(lambda x: K.max(x, axis=-1, keepdims=True))(input_feature)\n",
        "    concat = concatenate([avg_pool, max_pool])\n",
        "    attention_feature = Conv1D(1, kernel_size, padding='same', activation='sigmoid')(concat)\n",
        "    return multiply([input_feature, attention_feature])\n",
        "\n",
        "def transformer_encoder_layer(x, num_heads, dim_model, ff_dim):\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=dim_model)(x, x)\n",
        "    x = Add()([x, attn_output])\n",
        "    x = LayerNormalization()(x)\n",
        "    ff_output = Dense(ff_dim, activation='relu')(x)\n",
        "    ff_output = Dense(dim_model)(ff_output)\n",
        "    x = Add()([x, ff_output])\n",
        "    x = LayerNormalization()(x)\n",
        "    return x\n",
        "\n",
        "# def c1D(x, filters, kernel):\n",
        "#     x = Conv1D(filters, kernel_size=kernel, padding='same', use_bias=False)(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = LeakyReLU(alpha=0.2)(x)\n",
        "#     x = spatial_attention_layer(x)  # Apply spatial attention here\n",
        "#     return x\n",
        "\n",
        "\n",
        "def c1D(x,filters,kernel):\n",
        "    x = Conv1D(filters, kernel_size=kernel,padding='same',use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def block(x,filters):\n",
        "    x = c1D(x,filters,3)\n",
        "    x = c1D(x,filters,3)\n",
        "    return x\n",
        "\n",
        "def d1D(x,filters):\n",
        "    x = Dense(filters,use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def build_FM(frame_l=32,joint_n=22,joint_d=2,feat_d=231,filters=16):\n",
        "    M = Input(shape=(frame_l,feat_d))\n",
        "    P = Input(shape=(frame_l,joint_n,joint_d))\n",
        "    D = Input(name='D', shape=(frame_l,21))\n",
        "    A = Input(name='A', shape=(frame_l,21))\n",
        "\n",
        "    diff_slow, diff_fast = pose_motion(P, frame_l)\n",
        "\n",
        "    # diff_slow, _ = angle_distance(P, stride=1)\n",
        "    # diff_fast, _ = angle_distance(P, stride=2)\n",
        "    # print(diff_slow)\n",
        "    diff_slow = spatial_attention_layer(diff_slow)\n",
        "    diff_fast = spatial_attention_layer(diff_fast)\n",
        "\n",
        "    x = c1D(M,filters*2,1)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = c1D(x,filters,3)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "    x = c1D(x,filters,1)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x_d_slow = c1D(diff_slow,filters*2,1)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "    x_d_slow = c1D(x_d_slow,filters,3)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "    x_d_slow = c1D(x_d_slow,filters,1)\n",
        "    x_d_slow = MaxPool1D(2)(x_d_slow)\n",
        "    x_d_slow = SpatialDropout1D(0.1)(x_d_slow)\n",
        "\n",
        "    x_d_fast = c1D(diff_fast,filters*2,1)\n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "    x_d_fast = c1D(x_d_fast,filters,3)\n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "    x_d_fast = c1D(x_d_fast,filters,1)\n",
        "    x_d_fast = SpatialDropout1D(0.1)(x_d_fast)\n",
        "\n",
        "\n",
        "    d = c1D(D,filters*2,1)\n",
        "    d = SpatialDropout1D(0.1)(d)\n",
        "    d = c1D(d,filters,3)\n",
        "    d = SpatialDropout1D(0.1)(d)\n",
        "    d = c1D(d,filters,1)\n",
        "    d = MaxPooling1D(2)(d)\n",
        "    d = SpatialDropout1D(0.1)(d)\n",
        "\n",
        "\n",
        "    a = spatial_attention_layer(a)\n",
        "    a = c1D(A,filters*2,1)\n",
        "    a = SpatialDropout1D(0.1)(a)\n",
        "    a = c1D(a,filters,3)\n",
        "    a = SpatialDropout1D(0.1)(a)\n",
        "    a = c1D(a,filters,1)\n",
        "    a = MaxPooling1D(2)(a)\n",
        "    a = SpatialDropout1D(0.1)(a)\n",
        "\n",
        "    x = concatenate([x,x_d_slow,x_d_fast,d,a])\n",
        "    # x = transformer_encoder_layer(x, num_heads=4, dim_model=filters, ff_dim=filters * 4)\n",
        "\n",
        "    x = block(x,filters*2)\n",
        "    x = MaxPool1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x = block(x,filters*4)\n",
        "    x = MaxPool1D(2)(x)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    x = block(x,filters*8)\n",
        "    x = SpatialDropout1D(0.1)(x)\n",
        "\n",
        "    return Model(inputs=[M,P,D,A],outputs=x)\n",
        "\n",
        "\n",
        "def build_DD_Net(frame_l=32,joint_n=22,joint_d=3,feat_d=231,clc_num=14,filters=16):\n",
        "    M = Input(name='M', shape=(frame_l,feat_d))\n",
        "    P = Input(name='P', shape=(frame_l,joint_n,joint_d))\n",
        "    D = Input(name='D', shape=(frame_l,21))\n",
        "    A = Input(name='A', shape=(frame_l,21))\n",
        "\n",
        "    FM = build_FM(frame_l,joint_n,joint_d,feat_d,filters)\n",
        "\n",
        "    x = FM([M,P,D,A])\n",
        "\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "\n",
        "    x = d1D(x,128)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = d1D(x,128)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(clc_num, activation='softmax')(x)\n",
        "\n",
        "    ######################Self-supervised part\n",
        "    model = Model(inputs=[M,P,D,A],outputs=x)\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8J0YBi3xf7r",
        "outputId": "b8fba22a-fa1c-4fda-faf5-93c24c557a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "DD_Net = build_DD_Net(C.frame_l,C.joint_n,C.joint_d,C.feat_d,C.clc_coarse,C.filters)\n",
        "DD_Net.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 32, 66) (None, 16, 66)\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " M (InputLayer)              [(None, 32, 231)]            0         []                            \n",
            "                                                                                                  \n",
            " P (InputLayer)              [(None, 32, 22, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " D (InputLayer)              [(None, 32, 21)]             0         []                            \n",
            "                                                                                                  \n",
            " A (InputLayer)              [(None, 32, 21)]             0         []                            \n",
            "                                                                                                  \n",
            " model_2 (Functional)        (None, 4, 512)               1854094   ['M[0][0]',                   \n",
            "                                                                     'P[0][0]',                   \n",
            "                                                                     'D[0][0]',                   \n",
            "                                                                     'A[0][0]']                   \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Gl  (None, 512)                  0         ['model_2[0][0]']             \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 128)                  65536     ['global_max_pooling1d_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 128)                  512       ['dense_5[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_59 (LeakyReLU)  (None, 128)                  0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['leaky_re_lu_59[0][0]']      \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 128)                  16384     ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 128)                  512       ['dense_6[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_60 (LeakyReLU)  (None, 128)                  0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 128)                  0         ['leaky_re_lu_60[0][0]']      \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 14)                   1806      ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1938844 (7.40 MB)\n",
            "Trainable params: 1932188 (7.37 MB)\n",
            "Non-trainable params: 6656 (26.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428x7yhRxyjR"
      },
      "source": [
        "\n",
        "4. Load dataset (download GT_train_1.pkl and  GT_test_1.pkl from github )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPxB--e6UkeI",
        "outputId": "860aa21c-b087-4d24-a4c8-fabe3e7d3dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://github.com/fandulu/DD-Net/archive/master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-08 11:53:34--  https://github.com/fandulu/DD-Net/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/fandulu/DD-Net/zip/refs/heads/master [following]\n",
            "--2024-05-08 11:53:34--  https://codeload.github.com/fandulu/DD-Net/zip/refs/heads/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [             <=>    ]  79.09M  13.2MB/s    in 6.0s    \n",
            "\n",
            "2024-05-08 11:53:40 (13.2 MB/s) - ‘master.zip’ saved [82934337]\n",
            "\n",
            "Archive:  master.zip\n",
            "f26a9994b0bafc41096fa269eab89c2757d71499\n",
            "   creating: DD-Net-master/\n",
            "  inflating: DD-Net-master/.gitignore  \n",
            "   creating: DD-Net-master/JHMDB/\n",
            "  inflating: DD-Net-master/JHMDB/README.md  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_lite.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_1D_middle.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/jhmdb_data_preprocessing.ipynb  \n",
            "  inflating: DD-Net-master/JHMDB/utils.py  \n",
            "   creating: DD-Net-master/JHMDB/weights/\n",
            " extracting: DD-Net-master/JHMDB/weights/__init__.py  \n",
            "  inflating: DD-Net-master/LICENSE   \n",
            "  inflating: DD-Net-master/README.md  \n",
            "   creating: DD-Net-master/SHREC/\n",
            "  inflating: DD-Net-master/SHREC/README.md  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_coarse_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_coarse_1D_lite.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_data_preprocessing.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_fine_1D_heavy.ipynb  \n",
            "  inflating: DD-Net-master/SHREC/SHREC_fine_1D_lite.ipynb  \n",
            "   creating: DD-Net-master/SHREC/images/\n",
            "  inflating: DD-Net-master/SHREC/images/SHREC_14.png  \n",
            "  inflating: DD-Net-master/SHREC/images/SHREC_28.png  \n",
            "  inflating: DD-Net-master/SHREC/utils.py  \n",
            "   creating: DD-Net-master/SHREC/weights/\n",
            " extracting: DD-Net-master/SHREC/weights/.gitkeep  \n",
            " extracting: DD-Net-master/SHREC/weights/__init__.py  \n",
            "   creating: DD-Net-master/data/\n",
            "   creating: DD-Net-master/data/JHMDB/\n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_1.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_2.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_test_3.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_1.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_2.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/GT_train_3.pkl  \n",
            "  inflating: DD-Net-master/data/JHMDB/joint_positions.zip  \n",
            "  inflating: DD-Net-master/data/JHMDB/splits.zip  \n",
            "   creating: DD-Net-master/data/SHREC/\n",
            " extracting: DD-Net-master/data/SHREC/__init__.py  \n",
            "  inflating: DD-Net-master/data/SHREC/test.pickle  \n",
            "  inflating: DD-Net-master/data/SHREC/test.pkl  \n",
            "  inflating: DD-Net-master/data/SHREC/train.pickle  \n",
            "  inflating: DD-Net-master/data/SHREC/train.pkl  \n",
            "   creating: DD-Net-master/mics/\n",
            " extracting: DD-Net-master/mics/__init__.py  \n",
            "  inflating: DD-Net-master/mics/demo.png  \n",
            "  inflating: DD-Net-master/mics/look.gif  \n",
            "  inflating: DD-Net-master/mics/paper.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kbObgzuHD6f"
      },
      "source": [
        "5. Running codes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def angle_between_vectors(v1, v2):\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "    # Ensure input to arccos is within valid range\n",
        "    dot_product /= (norm_v1 * norm_v2)\n",
        "    dot_product = np.clip(dot_product, -1, 1)\n",
        "    return np.arccos(dot_product)\n",
        "\n",
        "# Sample data for 'a' representing hand points across time\n",
        "# a = np.random.rand(32, 22, 3)  # Assuming 5 time steps, 22 hand points, and 3 dimensions (x, y, z)\n",
        "\n",
        "bones = np.array([\n",
        "    [0, 1], [0, 2], [2, 3], [3, 4], [4, 5], [1, 6], [6, 7], [7, 8], [8, 9],\n",
        "    [1, 10], [10, 11], [11, 12], [12, 13], [1, 14], [14, 15], [15, 16], [16, 17],\n",
        "    [1, 18], [18, 19], [19, 20], [20, 21]\n",
        "])\n",
        "\n",
        "def angle_distance(a, stride=1):\n",
        "    # Initialize arrays to store angle differences and distance differences\n",
        "    num_frames = len(a)\n",
        "    num_bones = len(bones)\n",
        "    num_steps = (num_frames - 1) // stride\n",
        "\n",
        "    angle_differences = np.zeros((num_steps, num_bones))\n",
        "    distance_differences = np.zeros((num_steps, num_bones))\n",
        "\n",
        "    # Iterate through each time step in 'a' with the specified stride\n",
        "    for i in range(stride, num_frames, stride):\n",
        "        # Iterate through each bone in 'bones'\n",
        "        for j, bone in enumerate(bones):\n",
        "            # Extract the indices of the points connected by the bone\n",
        "            point1_index, point2_index = bone\n",
        "\n",
        "            # Get the coordinates of the points from the current and previous time steps\n",
        "            point1_coords_current = a[i][point1_index]\n",
        "            point2_coords_current = a[i][point2_index]\n",
        "            point1_coords_prev = a[i-stride][point1_index]\n",
        "            point2_coords_prev = a[i-stride][point2_index]\n",
        "\n",
        "            # Calculate the vectors representing the bones at the current and previous time steps\n",
        "            bone_vector_current = point2_coords_current - point1_coords_current\n",
        "            bone_vector_prev = point2_coords_prev - point1_coords_prev\n",
        "\n",
        "            # Calculate the angle between the bone vectors\n",
        "            angle = angle_between_vectors(bone_vector_current, bone_vector_prev)\n",
        "            angle_differences[i // stride - 1, j] = angle\n",
        "\n",
        "            # Calculate the distance between the bone endpoints at the current and previous time steps\n",
        "            distance = np.linalg.norm(point2_coords_current - point1_coords_current) - np.linalg.norm(point2_coords_prev - point1_coords_prev)\n",
        "            distance_differences[i // stride - 1, j] = distance\n",
        "\n",
        "    return angle_differences, distance_differences\n",
        "\n",
        "# # Print the angle and distance differences\n",
        "\n",
        "\n",
        "# angle_differences, distance_differences = angle_distance(X_1, stride=2)\n",
        "# print(\"Angle differences shape:\", angle_differences.shape)\n",
        "# print(\"Distance differences shape:\", distance_differences.shape)\n"
      ],
      "metadata": {
        "id": "J2hUAwUkNISX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baR9WIVLye-0",
        "outputId": "1bc1e5cb-f5f2-425e-92c1-e4b356d42665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Train = pickle.load(open(\"/content/DD-Net-master/data/SHREC/train.pkl\", \"rb\"))\n",
        "Test = pickle.load(open(\"/content/DD-Net-master/data/SHREC/test.pkl\", \"rb\"))\n",
        "\n",
        "X_0 = []\n",
        "X_1 = []\n",
        "D = []\n",
        "A = []\n",
        "Y = []\n",
        "\n",
        "for i in tqdm(range(len(Train['pose']))):\n",
        "    p1 = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
        "    p2 = np.copy(Train['pose'][i]).reshape([-1,22,3])\n",
        "\n",
        "    p1 = zoom(p1,target_l=32,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p1 = normlize_range(p1)\n",
        "\n",
        "    p2 = zoom(p2,target_l=33,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p2 = normlize_range(p2)\n",
        "\n",
        "    label = np.zeros(C.clc_coarse)\n",
        "    label[Train['coarse_label'][i]-1] = 1\n",
        "\n",
        "    M = get_CG(p1,C)\n",
        "    angle_differences, distance_differences = angle_distance(p2, stride=1)\n",
        "\n",
        "    D.append(distance_differences)\n",
        "    A.append(angle_differences)\n",
        "\n",
        "    X_0.append(M)\n",
        "    X_1.append(p1)\n",
        "    Y.append(label)\n",
        "\n",
        "X_0 = np.stack(X_0)\n",
        "X_1 = np.stack(X_1)\n",
        "Y = np.stack(Y)\n",
        "D = np.stack(D)\n",
        "A = np.stack(A)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1960 [00:00<?, ?it/s]<ipython-input-12-e313cf760854>:12: DeprecationWarning: Please use `zoom` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
            "  p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]\n",
            "100%|██████████| 1960/1960 [01:27<00:00, 22.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXQ-pXkmYzKx",
        "outputId": "cac9b6e3-c879-4a32-f666-5929166f2d03"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1960, 32, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in Train.keys():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_YIl8oWjy9S",
        "outputId": "75d1c0a1-ab66-4e5a-b6b7-52d3c5b0531f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pose\n",
            "coarse_label\n",
            "fine_label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pose = Train['pose']\n",
        "coarse_label = Train['coarse_label']\n",
        "fine_label = Train['fine_label']\n",
        "a = pose[0].reshape([-1,22,3])\n",
        "\n",
        "def zoom(p,target_l=33,joints_num=22,joints_dim=3):\n",
        "    l = p.shape[0]\n",
        "    p_new = np.empty([target_l,joints_num,joints_dim])\n",
        "    for m in range(joints_num):\n",
        "        for n in range(joints_dim):\n",
        "            p[:,m,n] = medfilt(p[:,m,n],3)\n",
        "            p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]\n",
        "    return p_new\n",
        "\n",
        "a = zoom(a)\n",
        "a = normlize_range(a)\n",
        "M = get_CG(a,C)\n",
        "print(a.shape)\n",
        "# a = a.reshape(32, 22, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3pLq4BplkTk",
        "outputId": "e21863d4-b09f-40e5-ae9e-2c4b9b7e5400"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33, 22, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-e313cf760854>:12: DeprecationWarning: Please use `zoom` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
            "  p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgD_qxkmihlj",
        "outputId": "e46d43f9-7ab5-4946-d325-781d024ceb13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test_0 = []\n",
        "X_test_1 = []\n",
        "Y_test = []\n",
        "D_test = []\n",
        "A_test = []\n",
        "\n",
        "for i in tqdm(range(len(Test['pose']))):\n",
        "    p1 = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
        "    p2 = np.copy(Test['pose'][i]).reshape([-1,22,3])\n",
        "\n",
        "    p1 = zoom(p1,target_l=32,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p1 = normlize_range(p1)\n",
        "\n",
        "    p2 = zoom(p2,target_l=33,joints_num=C.joint_n,joints_dim=C.joint_d)\n",
        "    p2 = normlize_range(p2)\n",
        "\n",
        "    label = np.zeros(C.clc_coarse)\n",
        "    label[Test['coarse_label'][i]-1] = 1\n",
        "\n",
        "    M = get_CG(p1,C)\n",
        "    angle_differences, distance_differences = angle_distance(p2, stride=1)\n",
        "\n",
        "    D_test.append(distance_differences)\n",
        "    A_test.append(angle_differences)\n",
        "    X_test_0.append(M)\n",
        "    X_test_1.append(p1)\n",
        "    Y_test.append(label)\n",
        "\n",
        "X_test_0 = np.stack(X_test_0)\n",
        "X_test_1 = np.stack(X_test_1)\n",
        "Y_test = np.stack(Y_test)\n",
        "D_test = np.stack(D_test)\n",
        "A_test = np.stack(A_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/840 [00:00<?, ?it/s]<ipython-input-12-e313cf760854>:12: DeprecationWarning: Please use `zoom` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
            "  p_new[:,m,n] = inter.zoom(p[:,m,n],target_l/l)[:target_l]\n",
            "100%|██████████| 840/840 [01:13<00:00, 11.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRwpfpB9zrB7",
        "outputId": "ce0f24b2-48f1-494f-c99b-20dc48be3750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# it may takes several times to reach the reported performance\n",
        "lr = 1e-4\n",
        "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
        "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
        "history = DD_Net.fit([X_0,X_1,D,A],Y,\n",
        "            batch_size=len(Y),\n",
        "            epochs=400,\n",
        "            verbose=True,\n",
        "            shuffle=True,\n",
        "            callbacks=[lrScheduler],\n",
        "            validation_data=[(X_test_0,X_test_1,D_test,A_test),Y_test]\n",
        "            )\n",
        "\n",
        "lr = 1e-4\n",
        "DD_Net.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
        "lrScheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, cooldown=5, min_lr=5e-6)\n",
        "history = DD_Net.fit([X_0,X_1,D,A],Y,\n",
        "            batch_size=len(Y),\n",
        "            epochs=500,\n",
        "            verbose=True,\n",
        "            shuffle=True,\n",
        "            callbacks=[lrScheduler],\n",
        "            validation_data=[(X_test_0,X_test_1,D_test,A_test),Y_test]\n",
        "            )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1/1 [==============================] - 16s 16s/step - loss: 3.4232 - accuracy: 0.0816 - val_loss: 2.6386 - val_accuracy: 0.0833 - lr: 1.0000e-04\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 3.3864 - accuracy: 0.0760 - val_loss: 2.6388 - val_accuracy: 0.0714 - lr: 1.0000e-04\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 3.2079 - accuracy: 0.0944 - val_loss: 2.6392 - val_accuracy: 0.0643 - lr: 1.0000e-04\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 3.2199 - accuracy: 0.0949 - val_loss: 2.6398 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 3.1225 - accuracy: 0.1020 - val_loss: 2.6402 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 3.0671 - accuracy: 0.1194 - val_loss: 2.6406 - val_accuracy: 0.0643 - lr: 1.0000e-04\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 3.0570 - accuracy: 0.1107 - val_loss: 2.6410 - val_accuracy: 0.0643 - lr: 1.0000e-04\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 2.9849 - accuracy: 0.1214 - val_loss: 2.6414 - val_accuracy: 0.0643 - lr: 1.0000e-04\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 2.8952 - accuracy: 0.1342 - val_loss: 2.6419 - val_accuracy: 0.0643 - lr: 1.0000e-04\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 2.8798 - accuracy: 0.1347 - val_loss: 2.6424 - val_accuracy: 0.0702 - lr: 1.0000e-04\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 2.8589 - accuracy: 0.1372 - val_loss: 2.6430 - val_accuracy: 0.0714 - lr: 1.0000e-04\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 2.8087 - accuracy: 0.1459 - val_loss: 2.6437 - val_accuracy: 0.0810 - lr: 1.0000e-04\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 2.7609 - accuracy: 0.1592 - val_loss: 2.6445 - val_accuracy: 0.0845 - lr: 1.0000e-04\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 2.7716 - accuracy: 0.1719 - val_loss: 2.6453 - val_accuracy: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 2.6936 - accuracy: 0.1658 - val_loss: 2.6463 - val_accuracy: 0.0643 - lr: 1.0000e-04\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 2.6627 - accuracy: 0.1679 - val_loss: 2.6474 - val_accuracy: 0.0643 - lr: 1.0000e-04\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 2.6541 - accuracy: 0.1740 - val_loss: 2.6486 - val_accuracy: 0.0619 - lr: 1.0000e-04\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 2.5957 - accuracy: 0.1821 - val_loss: 2.6499 - val_accuracy: 0.0631 - lr: 1.0000e-04\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 2.5764 - accuracy: 0.1867 - val_loss: 2.6513 - val_accuracy: 0.0631 - lr: 1.0000e-04\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 2.5957 - accuracy: 0.1908 - val_loss: 2.6528 - val_accuracy: 0.0631 - lr: 1.0000e-04\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 2.5564 - accuracy: 0.1995 - val_loss: 2.6543 - val_accuracy: 0.0619 - lr: 1.0000e-04\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 2.5394 - accuracy: 0.2133 - val_loss: 2.6558 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 2.4983 - accuracy: 0.2020 - val_loss: 2.6574 - val_accuracy: 0.0619 - lr: 1.0000e-04\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 2.4779 - accuracy: 0.2112 - val_loss: 2.6590 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 2.4639 - accuracy: 0.2189 - val_loss: 2.6607 - val_accuracy: 0.0619 - lr: 1.0000e-04\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 2.3993 - accuracy: 0.2403 - val_loss: 2.6625 - val_accuracy: 0.0619 - lr: 1.0000e-04\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 2.3794 - accuracy: 0.2418 - val_loss: 2.6642 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 2.3258 - accuracy: 0.2561 - val_loss: 2.6660 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 2.3534 - accuracy: 0.2577 - val_loss: 2.6678 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 2.2901 - accuracy: 0.2745 - val_loss: 2.6696 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 2.2557 - accuracy: 0.2770 - val_loss: 2.6714 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 2.2537 - accuracy: 0.2770 - val_loss: 2.6731 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 2.1904 - accuracy: 0.2878 - val_loss: 2.6749 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 2.1661 - accuracy: 0.2893 - val_loss: 2.6766 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 2.1498 - accuracy: 0.3036 - val_loss: 2.6784 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 2.1313 - accuracy: 0.3077 - val_loss: 2.6801 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 2.1229 - accuracy: 0.3056 - val_loss: 2.6819 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 2.0607 - accuracy: 0.3281 - val_loss: 2.6837 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 2.0460 - accuracy: 0.3316 - val_loss: 2.6855 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 2.0400 - accuracy: 0.3367 - val_loss: 2.6874 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 2.0076 - accuracy: 0.3541 - val_loss: 2.6892 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 1.9534 - accuracy: 0.3663 - val_loss: 2.6911 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 1.9253 - accuracy: 0.3791 - val_loss: 2.6930 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 1.9090 - accuracy: 0.3903 - val_loss: 2.6948 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 1.9007 - accuracy: 0.3867 - val_loss: 2.6967 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 1.8512 - accuracy: 0.3944 - val_loss: 2.6987 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 1.8398 - accuracy: 0.4107 - val_loss: 2.7006 - val_accuracy: 0.0607 - lr: 1.0000e-04\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 1.8001 - accuracy: 0.4122 - val_loss: 2.7025 - val_accuracy: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 1.7848 - accuracy: 0.4112 - val_loss: 2.7044 - val_accuracy: 0.0798 - lr: 1.0000e-04\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 1.7573 - accuracy: 0.4474 - val_loss: 2.7064 - val_accuracy: 0.0988 - lr: 1.0000e-04\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 1.7481 - accuracy: 0.4270 - val_loss: 2.7083 - val_accuracy: 0.1036 - lr: 1.0000e-04\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 1.6770 - accuracy: 0.4439 - val_loss: 2.7104 - val_accuracy: 0.1000 - lr: 1.0000e-04\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 1.7100 - accuracy: 0.4306 - val_loss: 2.7125 - val_accuracy: 0.0905 - lr: 1.0000e-04\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 1.6309 - accuracy: 0.4663 - val_loss: 2.7147 - val_accuracy: 0.0786 - lr: 1.0000e-04\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 1.6161 - accuracy: 0.4679 - val_loss: 2.7170 - val_accuracy: 0.0750 - lr: 1.0000e-04\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 1.6055 - accuracy: 0.4811 - val_loss: 2.7195 - val_accuracy: 0.0690 - lr: 1.0000e-04\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 1.5861 - accuracy: 0.4857 - val_loss: 2.7220 - val_accuracy: 0.0690 - lr: 1.0000e-04\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 1.5549 - accuracy: 0.5214 - val_loss: 2.7244 - val_accuracy: 0.0690 - lr: 1.0000e-04\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.5683 - accuracy: 0.5005 - val_loss: 2.7268 - val_accuracy: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 1.5266 - accuracy: 0.5092 - val_loss: 2.7293 - val_accuracy: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 1.4792 - accuracy: 0.5250 - val_loss: 2.7318 - val_accuracy: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 1.4776 - accuracy: 0.5332 - val_loss: 2.7345 - val_accuracy: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 1.4925 - accuracy: 0.5347 - val_loss: 2.7373 - val_accuracy: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 1.4185 - accuracy: 0.5510 - val_loss: 2.7401 - val_accuracy: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 1.4418 - accuracy: 0.5362 - val_loss: 2.7429 - val_accuracy: 0.0667 - lr: 1.0000e-04\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 1.4153 - accuracy: 0.5556 - val_loss: 2.7457 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 1.4008 - accuracy: 0.5638 - val_loss: 2.7484 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 1.3815 - accuracy: 0.5704 - val_loss: 2.7512 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 1.3601 - accuracy: 0.5821 - val_loss: 2.7541 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 1.3029 - accuracy: 0.5923 - val_loss: 2.7569 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 1.2951 - accuracy: 0.6026 - val_loss: 2.7596 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 1.3241 - accuracy: 0.5923 - val_loss: 2.7624 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 1.2995 - accuracy: 0.6087 - val_loss: 2.7652 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 1.2547 - accuracy: 0.6148 - val_loss: 2.7680 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 1.2539 - accuracy: 0.6219 - val_loss: 2.7709 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 1.2458 - accuracy: 0.6240 - val_loss: 2.7735 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 1.2136 - accuracy: 0.6393 - val_loss: 2.7760 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 1.2185 - accuracy: 0.6245 - val_loss: 2.7782 - val_accuracy: 0.0655 - lr: 1.0000e-04\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 1.1972 - accuracy: 0.6444 - val_loss: 2.7800 - val_accuracy: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 1.1696 - accuracy: 0.6500 - val_loss: 2.7819 - val_accuracy: 0.0679 - lr: 1.0000e-04\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 1.1692 - accuracy: 0.6459 - val_loss: 2.7840 - val_accuracy: 0.0702 - lr: 1.0000e-04\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 418ms/step - loss: 1.1696 - accuracy: 0.6510 - val_loss: 2.7861 - val_accuracy: 0.0690 - lr: 1.0000e-04\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 1.1480 - accuracy: 0.6602 - val_loss: 2.7883 - val_accuracy: 0.0738 - lr: 1.0000e-04\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.1055 - accuracy: 0.6811 - val_loss: 2.7904 - val_accuracy: 0.0774 - lr: 1.0000e-04\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 1.1259 - accuracy: 0.6663 - val_loss: 2.7928 - val_accuracy: 0.0833 - lr: 1.0000e-04\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 1.0993 - accuracy: 0.6867 - val_loss: 2.7950 - val_accuracy: 0.0964 - lr: 1.0000e-04\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 1.0922 - accuracy: 0.6816 - val_loss: 2.7973 - val_accuracy: 0.1036 - lr: 1.0000e-04\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 1.0908 - accuracy: 0.6832 - val_loss: 2.7999 - val_accuracy: 0.1095 - lr: 1.0000e-04\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 1.0442 - accuracy: 0.7046 - val_loss: 2.8025 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 1.0588 - accuracy: 0.6929 - val_loss: 2.8049 - val_accuracy: 0.1190 - lr: 1.0000e-04\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 1.0442 - accuracy: 0.7061 - val_loss: 2.8074 - val_accuracy: 0.1202 - lr: 1.0000e-04\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 1.0131 - accuracy: 0.7102 - val_loss: 2.8094 - val_accuracy: 0.1202 - lr: 1.0000e-04\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 1.0055 - accuracy: 0.7117 - val_loss: 2.8118 - val_accuracy: 0.1202 - lr: 1.0000e-04\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 1.0000 - accuracy: 0.7214 - val_loss: 2.8137 - val_accuracy: 0.1202 - lr: 1.0000e-04\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 1.0012 - accuracy: 0.7173 - val_loss: 2.8161 - val_accuracy: 0.1179 - lr: 1.0000e-04\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.9658 - accuracy: 0.7296 - val_loss: 2.8187 - val_accuracy: 0.1167 - lr: 1.0000e-04\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.9918 - accuracy: 0.7214 - val_loss: 2.8211 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.9757 - accuracy: 0.7260 - val_loss: 2.8233 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.9335 - accuracy: 0.7434 - val_loss: 2.8255 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.9377 - accuracy: 0.7454 - val_loss: 2.8276 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.9422 - accuracy: 0.7372 - val_loss: 2.8296 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.9414 - accuracy: 0.7480 - val_loss: 2.8313 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.9028 - accuracy: 0.7536 - val_loss: 2.8329 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.9020 - accuracy: 0.7628 - val_loss: 2.8341 - val_accuracy: 0.1143 - lr: 1.0000e-04\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 0.9047 - accuracy: 0.7617 - val_loss: 2.8356 - val_accuracy: 0.1131 - lr: 1.0000e-04\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.8796 - accuracy: 0.7694 - val_loss: 2.8373 - val_accuracy: 0.1131 - lr: 1.0000e-04\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 0.9042 - accuracy: 0.7551 - val_loss: 2.8391 - val_accuracy: 0.1107 - lr: 1.0000e-04\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.8690 - accuracy: 0.7643 - val_loss: 2.8406 - val_accuracy: 0.1107 - lr: 1.0000e-04\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.8732 - accuracy: 0.7663 - val_loss: 2.8425 - val_accuracy: 0.1107 - lr: 1.0000e-04\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.8146 - accuracy: 0.7852 - val_loss: 2.8448 - val_accuracy: 0.1107 - lr: 1.0000e-04\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.8334 - accuracy: 0.7801 - val_loss: 2.8471 - val_accuracy: 0.1095 - lr: 1.0000e-04\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 0.8457 - accuracy: 0.7837 - val_loss: 2.8498 - val_accuracy: 0.1095 - lr: 1.0000e-04\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 435ms/step - loss: 0.8360 - accuracy: 0.7760 - val_loss: 2.8525 - val_accuracy: 0.1095 - lr: 1.0000e-04\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.8290 - accuracy: 0.7760 - val_loss: 2.8548 - val_accuracy: 0.1095 - lr: 1.0000e-04\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.8246 - accuracy: 0.7883 - val_loss: 2.8573 - val_accuracy: 0.1095 - lr: 1.0000e-04\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 1s 518ms/step - loss: 0.7900 - accuracy: 0.8020 - val_loss: 2.8582 - val_accuracy: 0.1095 - lr: 5.0000e-05\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7947 - accuracy: 0.8026 - val_loss: 2.8594 - val_accuracy: 0.1095 - lr: 5.0000e-05\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.7983 - accuracy: 0.7939 - val_loss: 2.8603 - val_accuracy: 0.1095 - lr: 5.0000e-05\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.7941 - accuracy: 0.8020 - val_loss: 2.8612 - val_accuracy: 0.1095 - lr: 5.0000e-05\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.7926 - accuracy: 0.7985 - val_loss: 2.8621 - val_accuracy: 0.1095 - lr: 5.0000e-05\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.7773 - accuracy: 0.7985 - val_loss: 2.8629 - val_accuracy: 0.1095 - lr: 5.0000e-05\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.7818 - accuracy: 0.8051 - val_loss: 2.8640 - val_accuracy: 0.1095 - lr: 5.0000e-05\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.7645 - accuracy: 0.8046 - val_loss: 2.8650 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.7680 - accuracy: 0.8026 - val_loss: 2.8660 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.7701 - accuracy: 0.7980 - val_loss: 2.8670 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.7690 - accuracy: 0.8010 - val_loss: 2.8677 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.7858 - accuracy: 0.7985 - val_loss: 2.8682 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.7445 - accuracy: 0.8173 - val_loss: 2.8690 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.7780 - accuracy: 0.8061 - val_loss: 2.8696 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.7574 - accuracy: 0.8117 - val_loss: 2.8702 - val_accuracy: 0.1071 - lr: 5.0000e-05\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.7698 - accuracy: 0.8122 - val_loss: 2.8709 - val_accuracy: 0.1060 - lr: 5.0000e-05\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.7387 - accuracy: 0.8204 - val_loss: 2.8715 - val_accuracy: 0.1060 - lr: 5.0000e-05\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.7887 - accuracy: 0.7980 - val_loss: 2.8719 - val_accuracy: 0.1060 - lr: 5.0000e-05\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.7720 - accuracy: 0.7990 - val_loss: 2.8727 - val_accuracy: 0.1071 - lr: 5.0000e-05\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.7443 - accuracy: 0.8133 - val_loss: 2.8732 - val_accuracy: 0.1071 - lr: 5.0000e-05\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.7246 - accuracy: 0.8250 - val_loss: 2.8736 - val_accuracy: 0.1071 - lr: 5.0000e-05\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.7299 - accuracy: 0.8153 - val_loss: 2.8739 - val_accuracy: 0.1071 - lr: 5.0000e-05\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.7260 - accuracy: 0.8194 - val_loss: 2.8739 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.7146 - accuracy: 0.8240 - val_loss: 2.8738 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 0.7243 - accuracy: 0.8214 - val_loss: 2.8734 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 0.7159 - accuracy: 0.8179 - val_loss: 2.8733 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 0.7113 - accuracy: 0.8204 - val_loss: 2.8731 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.7215 - accuracy: 0.8173 - val_loss: 2.8729 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 0.7104 - accuracy: 0.8270 - val_loss: 2.8728 - val_accuracy: 0.1083 - lr: 5.0000e-05\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.7318 - accuracy: 0.8128 - val_loss: 2.8727 - val_accuracy: 0.1107 - lr: 5.0000e-05\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 0.7039 - accuracy: 0.8230 - val_loss: 2.8726 - val_accuracy: 0.1107 - lr: 5.0000e-05\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.7256 - accuracy: 0.8224 - val_loss: 2.8724 - val_accuracy: 0.1107 - lr: 5.0000e-05\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.7117 - accuracy: 0.8199 - val_loss: 2.8720 - val_accuracy: 0.1107 - lr: 5.0000e-05\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.7009 - accuracy: 0.8235 - val_loss: 2.8715 - val_accuracy: 0.1107 - lr: 5.0000e-05\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 256ms/step - loss: 0.6922 - accuracy: 0.8270 - val_loss: 2.8707 - val_accuracy: 0.1107 - lr: 5.0000e-05\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.7129 - accuracy: 0.8204 - val_loss: 2.8702 - val_accuracy: 0.1107 - lr: 5.0000e-05\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.6932 - accuracy: 0.8245 - val_loss: 2.8693 - val_accuracy: 0.1107 - lr: 5.0000e-05\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.6770 - accuracy: 0.8464 - val_loss: 2.8682 - val_accuracy: 0.1143 - lr: 5.0000e-05\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.6769 - accuracy: 0.8362 - val_loss: 2.8673 - val_accuracy: 0.1155 - lr: 5.0000e-05\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.6598 - accuracy: 0.8439 - val_loss: 2.8661 - val_accuracy: 0.1155 - lr: 5.0000e-05\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.6937 - accuracy: 0.8265 - val_loss: 2.8651 - val_accuracy: 0.1167 - lr: 5.0000e-05\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.6553 - accuracy: 0.8347 - val_loss: 2.8645 - val_accuracy: 0.1179 - lr: 5.0000e-05\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.6877 - accuracy: 0.8306 - val_loss: 2.8638 - val_accuracy: 0.1190 - lr: 5.0000e-05\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6692 - accuracy: 0.8393 - val_loss: 2.8628 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.6654 - accuracy: 0.8495 - val_loss: 2.8615 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.6499 - accuracy: 0.8490 - val_loss: 2.8607 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6715 - accuracy: 0.8337 - val_loss: 2.8593 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.6751 - accuracy: 0.8429 - val_loss: 2.8581 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.6571 - accuracy: 0.8408 - val_loss: 2.8569 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.6631 - accuracy: 0.8372 - val_loss: 2.8560 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.6443 - accuracy: 0.8403 - val_loss: 2.8544 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.6484 - accuracy: 0.8459 - val_loss: 2.8526 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.6553 - accuracy: 0.8429 - val_loss: 2.8507 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.6427 - accuracy: 0.8459 - val_loss: 2.8488 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.6207 - accuracy: 0.8526 - val_loss: 2.8470 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.6388 - accuracy: 0.8485 - val_loss: 2.8452 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.6409 - accuracy: 0.8582 - val_loss: 2.8435 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.6392 - accuracy: 0.8485 - val_loss: 2.8418 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.6177 - accuracy: 0.8622 - val_loss: 2.8400 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.6434 - accuracy: 0.8464 - val_loss: 2.8385 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.6183 - accuracy: 0.8571 - val_loss: 2.8366 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 0.6195 - accuracy: 0.8485 - val_loss: 2.8350 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.6045 - accuracy: 0.8653 - val_loss: 2.8330 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 449ms/step - loss: 0.6305 - accuracy: 0.8566 - val_loss: 2.8312 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 1s 642ms/step - loss: 0.5955 - accuracy: 0.8622 - val_loss: 2.8301 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.6142 - accuracy: 0.8520 - val_loss: 2.8296 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.6033 - accuracy: 0.8622 - val_loss: 2.8294 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 0.6172 - accuracy: 0.8602 - val_loss: 2.8291 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 0.5916 - accuracy: 0.8658 - val_loss: 2.8289 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.5943 - accuracy: 0.8561 - val_loss: 2.8280 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.5952 - accuracy: 0.8663 - val_loss: 2.8273 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.6283 - accuracy: 0.8566 - val_loss: 2.8255 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.6007 - accuracy: 0.8673 - val_loss: 2.8236 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.6044 - accuracy: 0.8592 - val_loss: 2.8216 - val_accuracy: 0.1202 - lr: 5.0000e-05\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.5997 - accuracy: 0.8719 - val_loss: 2.8196 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6085 - accuracy: 0.8587 - val_loss: 2.8176 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.5720 - accuracy: 0.8776 - val_loss: 2.8155 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.5640 - accuracy: 0.8673 - val_loss: 2.8134 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.5851 - accuracy: 0.8638 - val_loss: 2.8113 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.5707 - accuracy: 0.8724 - val_loss: 2.8090 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.5928 - accuracy: 0.8612 - val_loss: 2.8069 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.5897 - accuracy: 0.8577 - val_loss: 2.8045 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.5887 - accuracy: 0.8597 - val_loss: 2.8022 - val_accuracy: 0.1202 - lr: 2.5000e-05\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.5869 - accuracy: 0.8714 - val_loss: 2.7997 - val_accuracy: 0.1202 - lr: 1.2500e-05\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.5984 - accuracy: 0.8612 - val_loss: 2.7971 - val_accuracy: 0.1214 - lr: 1.2500e-05\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.5891 - accuracy: 0.8561 - val_loss: 2.7946 - val_accuracy: 0.1214 - lr: 1.2500e-05\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.5927 - accuracy: 0.8612 - val_loss: 2.7918 - val_accuracy: 0.1214 - lr: 1.2500e-05\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.5667 - accuracy: 0.8750 - val_loss: 2.7894 - val_accuracy: 0.1214 - lr: 1.2500e-05\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.5799 - accuracy: 0.8694 - val_loss: 2.7869 - val_accuracy: 0.1226 - lr: 1.2500e-05\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.5876 - accuracy: 0.8709 - val_loss: 2.7848 - val_accuracy: 0.1226 - lr: 1.2500e-05\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5753 - accuracy: 0.8648 - val_loss: 2.7824 - val_accuracy: 0.1238 - lr: 1.2500e-05\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.5924 - accuracy: 0.8526 - val_loss: 2.7800 - val_accuracy: 0.1238 - lr: 1.2500e-05\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.5523 - accuracy: 0.8770 - val_loss: 2.7776 - val_accuracy: 0.1250 - lr: 6.2500e-06\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.5733 - accuracy: 0.8740 - val_loss: 2.7753 - val_accuracy: 0.1250 - lr: 6.2500e-06\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.5525 - accuracy: 0.8811 - val_loss: 2.7729 - val_accuracy: 0.1262 - lr: 6.2500e-06\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.5743 - accuracy: 0.8673 - val_loss: 2.7705 - val_accuracy: 0.1262 - lr: 6.2500e-06\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5671 - accuracy: 0.8760 - val_loss: 2.7680 - val_accuracy: 0.1262 - lr: 6.2500e-06\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.5516 - accuracy: 0.8781 - val_loss: 2.7657 - val_accuracy: 0.1274 - lr: 6.2500e-06\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.5770 - accuracy: 0.8633 - val_loss: 2.7631 - val_accuracy: 0.1274 - lr: 6.2500e-06\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.5974 - accuracy: 0.8612 - val_loss: 2.7606 - val_accuracy: 0.1274 - lr: 6.2500e-06\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.5577 - accuracy: 0.8832 - val_loss: 2.7582 - val_accuracy: 0.1274 - lr: 6.2500e-06\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.5739 - accuracy: 0.8673 - val_loss: 2.7558 - val_accuracy: 0.1274 - lr: 6.2500e-06\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.5826 - accuracy: 0.8709 - val_loss: 2.7532 - val_accuracy: 0.1274 - lr: 6.2500e-06\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.5930 - accuracy: 0.8546 - val_loss: 2.7508 - val_accuracy: 0.1274 - lr: 5.0000e-06\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.5682 - accuracy: 0.8714 - val_loss: 2.7486 - val_accuracy: 0.1274 - lr: 5.0000e-06\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.5544 - accuracy: 0.8791 - val_loss: 2.7463 - val_accuracy: 0.1286 - lr: 5.0000e-06\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.5758 - accuracy: 0.8699 - val_loss: 2.7437 - val_accuracy: 0.1286 - lr: 5.0000e-06\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.5809 - accuracy: 0.8709 - val_loss: 2.7414 - val_accuracy: 0.1286 - lr: 5.0000e-06\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.5768 - accuracy: 0.8699 - val_loss: 2.7390 - val_accuracy: 0.1286 - lr: 5.0000e-06\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.5710 - accuracy: 0.8709 - val_loss: 2.7366 - val_accuracy: 0.1286 - lr: 5.0000e-06\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.5645 - accuracy: 0.8709 - val_loss: 2.7341 - val_accuracy: 0.1286 - lr: 5.0000e-06\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.5967 - accuracy: 0.8633 - val_loss: 2.7320 - val_accuracy: 0.1286 - lr: 5.0000e-06\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.5580 - accuracy: 0.8801 - val_loss: 2.7297 - val_accuracy: 0.1298 - lr: 5.0000e-06\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.5856 - accuracy: 0.8679 - val_loss: 2.7272 - val_accuracy: 0.1298 - lr: 5.0000e-06\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.5765 - accuracy: 0.8684 - val_loss: 2.7247 - val_accuracy: 0.1298 - lr: 5.0000e-06\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.5758 - accuracy: 0.8704 - val_loss: 2.7224 - val_accuracy: 0.1298 - lr: 5.0000e-06\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.5794 - accuracy: 0.8602 - val_loss: 2.7200 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.5844 - accuracy: 0.8602 - val_loss: 2.7177 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.5730 - accuracy: 0.8694 - val_loss: 2.7152 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.5655 - accuracy: 0.8776 - val_loss: 2.7126 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.5625 - accuracy: 0.8791 - val_loss: 2.7102 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.5799 - accuracy: 0.8622 - val_loss: 2.7079 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.5774 - accuracy: 0.8714 - val_loss: 2.7054 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.5784 - accuracy: 0.8638 - val_loss: 2.7031 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.5751 - accuracy: 0.8689 - val_loss: 2.7006 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.5550 - accuracy: 0.8730 - val_loss: 2.6981 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.5794 - accuracy: 0.8694 - val_loss: 2.6957 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.5608 - accuracy: 0.8643 - val_loss: 2.6930 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5566 - accuracy: 0.8684 - val_loss: 2.6904 - val_accuracy: 0.1321 - lr: 5.0000e-06\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.5524 - accuracy: 0.8806 - val_loss: 2.6880 - val_accuracy: 0.1333 - lr: 5.0000e-06\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.5548 - accuracy: 0.8781 - val_loss: 2.6854 - val_accuracy: 0.1333 - lr: 5.0000e-06\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5679 - accuracy: 0.8776 - val_loss: 2.6826 - val_accuracy: 0.1333 - lr: 5.0000e-06\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.5604 - accuracy: 0.8704 - val_loss: 2.6799 - val_accuracy: 0.1333 - lr: 5.0000e-06\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 260ms/step - loss: 0.5425 - accuracy: 0.8760 - val_loss: 2.6771 - val_accuracy: 0.1333 - lr: 5.0000e-06\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.5652 - accuracy: 0.8745 - val_loss: 2.6742 - val_accuracy: 0.1333 - lr: 5.0000e-06\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.5772 - accuracy: 0.8663 - val_loss: 2.6716 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.5840 - accuracy: 0.8704 - val_loss: 2.6690 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.5736 - accuracy: 0.8694 - val_loss: 2.6666 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.5730 - accuracy: 0.8694 - val_loss: 2.6640 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.5563 - accuracy: 0.8638 - val_loss: 2.6614 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5613 - accuracy: 0.8704 - val_loss: 2.6588 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.5519 - accuracy: 0.8821 - val_loss: 2.6562 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.5521 - accuracy: 0.8689 - val_loss: 2.6536 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.5578 - accuracy: 0.8842 - val_loss: 2.6508 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5451 - accuracy: 0.8776 - val_loss: 2.6479 - val_accuracy: 0.1357 - lr: 5.0000e-06\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.5355 - accuracy: 0.8847 - val_loss: 2.6452 - val_accuracy: 0.1369 - lr: 5.0000e-06\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.5680 - accuracy: 0.8668 - val_loss: 2.6426 - val_accuracy: 0.1369 - lr: 5.0000e-06\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5846 - accuracy: 0.8679 - val_loss: 2.6400 - val_accuracy: 0.1381 - lr: 5.0000e-06\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.5613 - accuracy: 0.8643 - val_loss: 2.6370 - val_accuracy: 0.1381 - lr: 5.0000e-06\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.5577 - accuracy: 0.8786 - val_loss: 2.6343 - val_accuracy: 0.1393 - lr: 5.0000e-06\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.5819 - accuracy: 0.8745 - val_loss: 2.6317 - val_accuracy: 0.1393 - lr: 5.0000e-06\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.5358 - accuracy: 0.8791 - val_loss: 2.6289 - val_accuracy: 0.1417 - lr: 5.0000e-06\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.5490 - accuracy: 0.8827 - val_loss: 2.6263 - val_accuracy: 0.1417 - lr: 5.0000e-06\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.5755 - accuracy: 0.8755 - val_loss: 2.6237 - val_accuracy: 0.1429 - lr: 5.0000e-06\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.5547 - accuracy: 0.8704 - val_loss: 2.6208 - val_accuracy: 0.1440 - lr: 5.0000e-06\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.5695 - accuracy: 0.8781 - val_loss: 2.6178 - val_accuracy: 0.1452 - lr: 5.0000e-06\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.5801 - accuracy: 0.8694 - val_loss: 2.6152 - val_accuracy: 0.1452 - lr: 5.0000e-06\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.5764 - accuracy: 0.8694 - val_loss: 2.6124 - val_accuracy: 0.1452 - lr: 5.0000e-06\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.5724 - accuracy: 0.8740 - val_loss: 2.6096 - val_accuracy: 0.1452 - lr: 5.0000e-06\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.5555 - accuracy: 0.8786 - val_loss: 2.6066 - val_accuracy: 0.1464 - lr: 5.0000e-06\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.5787 - accuracy: 0.8633 - val_loss: 2.6037 - val_accuracy: 0.1464 - lr: 5.0000e-06\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5319 - accuracy: 0.8832 - val_loss: 2.6008 - val_accuracy: 0.1488 - lr: 5.0000e-06\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.5563 - accuracy: 0.8832 - val_loss: 2.5979 - val_accuracy: 0.1488 - lr: 5.0000e-06\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.5658 - accuracy: 0.8760 - val_loss: 2.5950 - val_accuracy: 0.1500 - lr: 5.0000e-06\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.5608 - accuracy: 0.8760 - val_loss: 2.5921 - val_accuracy: 0.1500 - lr: 5.0000e-06\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.5604 - accuracy: 0.8735 - val_loss: 2.5891 - val_accuracy: 0.1512 - lr: 5.0000e-06\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.5674 - accuracy: 0.8755 - val_loss: 2.5862 - val_accuracy: 0.1524 - lr: 5.0000e-06\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.5720 - accuracy: 0.8633 - val_loss: 2.5833 - val_accuracy: 0.1524 - lr: 5.0000e-06\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5714 - accuracy: 0.8689 - val_loss: 2.5804 - val_accuracy: 0.1536 - lr: 5.0000e-06\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5656 - accuracy: 0.8765 - val_loss: 2.5775 - val_accuracy: 0.1536 - lr: 5.0000e-06\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.5579 - accuracy: 0.8694 - val_loss: 2.5747 - val_accuracy: 0.1548 - lr: 5.0000e-06\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.5587 - accuracy: 0.8786 - val_loss: 2.5719 - val_accuracy: 0.1560 - lr: 5.0000e-06\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.5924 - accuracy: 0.8638 - val_loss: 2.5691 - val_accuracy: 0.1583 - lr: 5.0000e-06\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.5726 - accuracy: 0.8719 - val_loss: 2.5664 - val_accuracy: 0.1583 - lr: 5.0000e-06\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.5466 - accuracy: 0.8821 - val_loss: 2.5635 - val_accuracy: 0.1607 - lr: 5.0000e-06\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.5440 - accuracy: 0.8796 - val_loss: 2.5605 - val_accuracy: 0.1607 - lr: 5.0000e-06\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.5364 - accuracy: 0.8801 - val_loss: 2.5577 - val_accuracy: 0.1631 - lr: 5.0000e-06\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.5413 - accuracy: 0.8770 - val_loss: 2.5549 - val_accuracy: 0.1631 - lr: 5.0000e-06\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.5658 - accuracy: 0.8745 - val_loss: 2.5519 - val_accuracy: 0.1643 - lr: 5.0000e-06\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.5589 - accuracy: 0.8673 - val_loss: 2.5487 - val_accuracy: 0.1643 - lr: 5.0000e-06\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.5855 - accuracy: 0.8638 - val_loss: 2.5456 - val_accuracy: 0.1667 - lr: 5.0000e-06\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5726 - accuracy: 0.8704 - val_loss: 2.5426 - val_accuracy: 0.1679 - lr: 5.0000e-06\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.5629 - accuracy: 0.8750 - val_loss: 2.5396 - val_accuracy: 0.1690 - lr: 5.0000e-06\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.5543 - accuracy: 0.8806 - val_loss: 2.5364 - val_accuracy: 0.1714 - lr: 5.0000e-06\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5485 - accuracy: 0.8755 - val_loss: 2.5334 - val_accuracy: 0.1714 - lr: 5.0000e-06\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.5182 - accuracy: 0.8857 - val_loss: 2.5303 - val_accuracy: 0.1726 - lr: 5.0000e-06\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.5513 - accuracy: 0.8781 - val_loss: 2.5272 - val_accuracy: 0.1738 - lr: 5.0000e-06\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.5524 - accuracy: 0.8811 - val_loss: 2.5242 - val_accuracy: 0.1762 - lr: 5.0000e-06\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.5609 - accuracy: 0.8760 - val_loss: 2.5211 - val_accuracy: 0.1774 - lr: 5.0000e-06\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.5389 - accuracy: 0.8776 - val_loss: 2.5181 - val_accuracy: 0.1774 - lr: 5.0000e-06\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.5331 - accuracy: 0.8852 - val_loss: 2.5149 - val_accuracy: 0.1774 - lr: 5.0000e-06\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.5688 - accuracy: 0.8719 - val_loss: 2.5115 - val_accuracy: 0.1786 - lr: 5.0000e-06\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 0.5445 - accuracy: 0.8816 - val_loss: 2.5082 - val_accuracy: 0.1798 - lr: 5.0000e-06\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.5730 - accuracy: 0.8673 - val_loss: 2.5046 - val_accuracy: 0.1798 - lr: 5.0000e-06\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.5485 - accuracy: 0.8714 - val_loss: 2.5013 - val_accuracy: 0.1810 - lr: 5.0000e-06\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.5554 - accuracy: 0.8745 - val_loss: 2.4980 - val_accuracy: 0.1845 - lr: 5.0000e-06\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 0.5413 - accuracy: 0.8847 - val_loss: 2.4947 - val_accuracy: 0.1869 - lr: 5.0000e-06\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 0.5557 - accuracy: 0.8888 - val_loss: 2.4912 - val_accuracy: 0.1869 - lr: 5.0000e-06\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5623 - accuracy: 0.8689 - val_loss: 2.4878 - val_accuracy: 0.1893 - lr: 5.0000e-06\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.5425 - accuracy: 0.8816 - val_loss: 2.4843 - val_accuracy: 0.1893 - lr: 5.0000e-06\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.5542 - accuracy: 0.8786 - val_loss: 2.4808 - val_accuracy: 0.1893 - lr: 5.0000e-06\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.5511 - accuracy: 0.8791 - val_loss: 2.4771 - val_accuracy: 0.1893 - lr: 5.0000e-06\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.5375 - accuracy: 0.8908 - val_loss: 2.4737 - val_accuracy: 0.1905 - lr: 5.0000e-06\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.5625 - accuracy: 0.8699 - val_loss: 2.4702 - val_accuracy: 0.1905 - lr: 5.0000e-06\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.5604 - accuracy: 0.8821 - val_loss: 2.4666 - val_accuracy: 0.1905 - lr: 5.0000e-06\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.5353 - accuracy: 0.8750 - val_loss: 2.4631 - val_accuracy: 0.1917 - lr: 5.0000e-06\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5498 - accuracy: 0.8786 - val_loss: 2.4595 - val_accuracy: 0.1929 - lr: 5.0000e-06\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.5299 - accuracy: 0.8832 - val_loss: 2.4560 - val_accuracy: 0.1929 - lr: 5.0000e-06\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.5501 - accuracy: 0.8760 - val_loss: 2.4523 - val_accuracy: 0.1940 - lr: 5.0000e-06\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.5641 - accuracy: 0.8714 - val_loss: 2.4487 - val_accuracy: 0.1964 - lr: 5.0000e-06\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 0.5776 - accuracy: 0.8735 - val_loss: 2.4452 - val_accuracy: 0.1964 - lr: 5.0000e-06\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.5534 - accuracy: 0.8740 - val_loss: 2.4415 - val_accuracy: 0.1976 - lr: 5.0000e-06\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.5683 - accuracy: 0.8781 - val_loss: 2.4379 - val_accuracy: 0.2000 - lr: 5.0000e-06\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5432 - accuracy: 0.8862 - val_loss: 2.4341 - val_accuracy: 0.2000 - lr: 5.0000e-06\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.5165 - accuracy: 0.8934 - val_loss: 2.4304 - val_accuracy: 0.2012 - lr: 5.0000e-06\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.5445 - accuracy: 0.8791 - val_loss: 2.4265 - val_accuracy: 0.2048 - lr: 5.0000e-06\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.5518 - accuracy: 0.8811 - val_loss: 2.4227 - val_accuracy: 0.2048 - lr: 5.0000e-06\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.5709 - accuracy: 0.8679 - val_loss: 2.4187 - val_accuracy: 0.2048 - lr: 5.0000e-06\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 263ms/step - loss: 0.5516 - accuracy: 0.8760 - val_loss: 2.4146 - val_accuracy: 0.2071 - lr: 5.0000e-06\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.5213 - accuracy: 0.8867 - val_loss: 2.4106 - val_accuracy: 0.2071 - lr: 5.0000e-06\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.5366 - accuracy: 0.8857 - val_loss: 2.4064 - val_accuracy: 0.2083 - lr: 5.0000e-06\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.5247 - accuracy: 0.8888 - val_loss: 2.4021 - val_accuracy: 0.2083 - lr: 5.0000e-06\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.5305 - accuracy: 0.8806 - val_loss: 2.3980 - val_accuracy: 0.2107 - lr: 5.0000e-06\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.5471 - accuracy: 0.8801 - val_loss: 2.3938 - val_accuracy: 0.2119 - lr: 5.0000e-06\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.5479 - accuracy: 0.8857 - val_loss: 2.3896 - val_accuracy: 0.2143 - lr: 5.0000e-06\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.5552 - accuracy: 0.8791 - val_loss: 2.3855 - val_accuracy: 0.2167 - lr: 5.0000e-06\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.5491 - accuracy: 0.8821 - val_loss: 2.3813 - val_accuracy: 0.2179 - lr: 5.0000e-06\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5588 - accuracy: 0.8689 - val_loss: 2.3770 - val_accuracy: 0.2179 - lr: 5.0000e-06\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 269ms/step - loss: 0.5446 - accuracy: 0.8827 - val_loss: 2.3726 - val_accuracy: 0.2214 - lr: 5.0000e-06\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.5450 - accuracy: 0.8770 - val_loss: 2.3682 - val_accuracy: 0.2238 - lr: 5.0000e-06\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.5646 - accuracy: 0.8668 - val_loss: 2.3637 - val_accuracy: 0.2262 - lr: 5.0000e-06\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5535 - accuracy: 0.8770 - val_loss: 2.3592 - val_accuracy: 0.2298 - lr: 5.0000e-06\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.5326 - accuracy: 0.8811 - val_loss: 2.3548 - val_accuracy: 0.2310 - lr: 5.0000e-06\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.5405 - accuracy: 0.8791 - val_loss: 2.3501 - val_accuracy: 0.2310 - lr: 5.0000e-06\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.5455 - accuracy: 0.8811 - val_loss: 2.3456 - val_accuracy: 0.2345 - lr: 5.0000e-06\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.5812 - accuracy: 0.8653 - val_loss: 2.3409 - val_accuracy: 0.2345 - lr: 5.0000e-06\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.5553 - accuracy: 0.8821 - val_loss: 2.3362 - val_accuracy: 0.2381 - lr: 5.0000e-06\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.5389 - accuracy: 0.8857 - val_loss: 2.3317 - val_accuracy: 0.2381 - lr: 5.0000e-06\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.5369 - accuracy: 0.8811 - val_loss: 2.3271 - val_accuracy: 0.2381 - lr: 5.0000e-06\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 0.5493 - accuracy: 0.8730 - val_loss: 2.3223 - val_accuracy: 0.2393 - lr: 5.0000e-06\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.5290 - accuracy: 0.8934 - val_loss: 2.3177 - val_accuracy: 0.2417 - lr: 5.0000e-06\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.5452 - accuracy: 0.8786 - val_loss: 2.3128 - val_accuracy: 0.2440 - lr: 5.0000e-06\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 0.5380 - accuracy: 0.8837 - val_loss: 2.3080 - val_accuracy: 0.2452 - lr: 5.0000e-06\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.5432 - accuracy: 0.8811 - val_loss: 2.3034 - val_accuracy: 0.2464 - lr: 5.0000e-06\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5601 - accuracy: 0.8730 - val_loss: 2.2986 - val_accuracy: 0.2464 - lr: 5.0000e-06\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.5469 - accuracy: 0.8801 - val_loss: 2.2939 - val_accuracy: 0.2488 - lr: 5.0000e-06\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.5559 - accuracy: 0.8745 - val_loss: 2.2891 - val_accuracy: 0.2524 - lr: 5.0000e-06\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.5439 - accuracy: 0.8755 - val_loss: 2.2843 - val_accuracy: 0.2536 - lr: 5.0000e-06\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.5374 - accuracy: 0.8791 - val_loss: 2.2791 - val_accuracy: 0.2536 - lr: 5.0000e-06\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.5176 - accuracy: 0.8842 - val_loss: 2.2741 - val_accuracy: 0.2536 - lr: 5.0000e-06\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.5559 - accuracy: 0.8776 - val_loss: 2.2691 - val_accuracy: 0.2548 - lr: 5.0000e-06\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.5508 - accuracy: 0.8821 - val_loss: 2.2639 - val_accuracy: 0.2571 - lr: 5.0000e-06\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.5450 - accuracy: 0.8801 - val_loss: 2.2589 - val_accuracy: 0.2571 - lr: 5.0000e-06\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.5344 - accuracy: 0.8872 - val_loss: 2.2539 - val_accuracy: 0.2583 - lr: 5.0000e-06\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.5178 - accuracy: 0.8995 - val_loss: 2.2486 - val_accuracy: 0.2607 - lr: 5.0000e-06\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.5394 - accuracy: 0.8862 - val_loss: 2.2433 - val_accuracy: 0.2631 - lr: 5.0000e-06\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.5509 - accuracy: 0.8709 - val_loss: 2.2377 - val_accuracy: 0.2631 - lr: 5.0000e-06\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.5560 - accuracy: 0.8699 - val_loss: 2.2323 - val_accuracy: 0.2643 - lr: 5.0000e-06\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.5402 - accuracy: 0.8842 - val_loss: 2.2268 - val_accuracy: 0.2655 - lr: 5.0000e-06\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.5605 - accuracy: 0.8745 - val_loss: 2.2212 - val_accuracy: 0.2679 - lr: 5.0000e-06\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.5371 - accuracy: 0.8786 - val_loss: 2.2158 - val_accuracy: 0.2679 - lr: 5.0000e-06\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.5368 - accuracy: 0.8857 - val_loss: 2.2104 - val_accuracy: 0.2690 - lr: 5.0000e-06\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.5288 - accuracy: 0.8929 - val_loss: 2.2049 - val_accuracy: 0.2702 - lr: 5.0000e-06\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5413 - accuracy: 0.8781 - val_loss: 2.1994 - val_accuracy: 0.2714 - lr: 5.0000e-06\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 0.5243 - accuracy: 0.8913 - val_loss: 2.1939 - val_accuracy: 0.2750 - lr: 5.0000e-06\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.5407 - accuracy: 0.8862 - val_loss: 2.1884 - val_accuracy: 0.2786 - lr: 5.0000e-06\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.5388 - accuracy: 0.8867 - val_loss: 2.1829 - val_accuracy: 0.2810 - lr: 5.0000e-06\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.5238 - accuracy: 0.8878 - val_loss: 2.1773 - val_accuracy: 0.2833 - lr: 5.0000e-06\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5428 - accuracy: 0.8872 - val_loss: 2.1717 - val_accuracy: 0.2845 - lr: 5.0000e-06\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.5206 - accuracy: 0.8878 - val_loss: 2.1657 - val_accuracy: 0.2857 - lr: 5.0000e-06\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.5286 - accuracy: 0.8806 - val_loss: 2.1599 - val_accuracy: 0.2857 - lr: 5.0000e-06\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.5303 - accuracy: 0.8832 - val_loss: 2.1540 - val_accuracy: 0.2857 - lr: 5.0000e-06\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.5438 - accuracy: 0.8755 - val_loss: 2.1480 - val_accuracy: 0.2857 - lr: 5.0000e-06\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.5216 - accuracy: 0.8821 - val_loss: 2.1420 - val_accuracy: 0.2869 - lr: 5.0000e-06\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.5461 - accuracy: 0.8816 - val_loss: 2.1361 - val_accuracy: 0.2869 - lr: 5.0000e-06\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.5355 - accuracy: 0.8796 - val_loss: 2.1300 - val_accuracy: 0.2893 - lr: 5.0000e-06\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.5350 - accuracy: 0.8893 - val_loss: 2.1239 - val_accuracy: 0.2905 - lr: 5.0000e-06\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.5205 - accuracy: 0.8832 - val_loss: 2.1175 - val_accuracy: 0.2917 - lr: 5.0000e-06\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.5341 - accuracy: 0.8786 - val_loss: 2.1112 - val_accuracy: 0.2940 - lr: 5.0000e-06\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.5408 - accuracy: 0.8760 - val_loss: 2.1049 - val_accuracy: 0.2988 - lr: 5.0000e-06\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.5482 - accuracy: 0.8837 - val_loss: 2.0988 - val_accuracy: 0.3000 - lr: 5.0000e-06\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.5463 - accuracy: 0.8811 - val_loss: 2.0925 - val_accuracy: 0.3000 - lr: 5.0000e-06\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.5392 - accuracy: 0.8862 - val_loss: 2.0861 - val_accuracy: 0.3012 - lr: 5.0000e-06\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.5317 - accuracy: 0.8842 - val_loss: 2.0797 - val_accuracy: 0.3060 - lr: 5.0000e-06\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.5229 - accuracy: 0.8908 - val_loss: 2.0733 - val_accuracy: 0.3119 - lr: 5.0000e-06\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 16s 16s/step - loss: 0.5288 - accuracy: 0.8918 - val_loss: 2.0668 - val_accuracy: 0.3167 - lr: 1.0000e-04\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 382ms/step - loss: 0.5136 - accuracy: 0.8923 - val_loss: 2.0496 - val_accuracy: 0.3226 - lr: 1.0000e-04\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.5177 - accuracy: 0.8888 - val_loss: 2.0314 - val_accuracy: 0.3262 - lr: 1.0000e-04\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.5161 - accuracy: 0.8913 - val_loss: 2.0176 - val_accuracy: 0.3357 - lr: 1.0000e-04\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.5033 - accuracy: 0.8990 - val_loss: 1.9995 - val_accuracy: 0.3417 - lr: 1.0000e-04\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.5250 - accuracy: 0.8791 - val_loss: 1.9794 - val_accuracy: 0.3476 - lr: 1.0000e-04\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 0.4863 - accuracy: 0.8985 - val_loss: 1.9602 - val_accuracy: 0.3560 - lr: 1.0000e-04\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.5032 - accuracy: 0.8883 - val_loss: 1.9431 - val_accuracy: 0.3595 - lr: 1.0000e-04\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.4733 - accuracy: 0.9015 - val_loss: 1.9274 - val_accuracy: 0.3655 - lr: 1.0000e-04\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.4545 - accuracy: 0.9071 - val_loss: 1.9180 - val_accuracy: 0.3679 - lr: 1.0000e-04\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.4690 - accuracy: 0.9051 - val_loss: 1.9105 - val_accuracy: 0.3679 - lr: 1.0000e-04\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.4616 - accuracy: 0.9133 - val_loss: 1.9011 - val_accuracy: 0.3798 - lr: 1.0000e-04\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.4610 - accuracy: 0.9036 - val_loss: 1.8908 - val_accuracy: 0.3798 - lr: 1.0000e-04\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.4502 - accuracy: 0.9092 - val_loss: 1.8823 - val_accuracy: 0.3881 - lr: 1.0000e-04\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.4402 - accuracy: 0.9077 - val_loss: 1.8725 - val_accuracy: 0.3893 - lr: 1.0000e-04\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.4372 - accuracy: 0.9143 - val_loss: 1.8626 - val_accuracy: 0.3964 - lr: 1.0000e-04\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.4409 - accuracy: 0.9102 - val_loss: 1.8542 - val_accuracy: 0.3976 - lr: 1.0000e-04\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.4344 - accuracy: 0.9117 - val_loss: 1.8421 - val_accuracy: 0.3988 - lr: 1.0000e-04\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.4195 - accuracy: 0.9204 - val_loss: 1.8253 - val_accuracy: 0.4036 - lr: 1.0000e-04\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.4101 - accuracy: 0.9204 - val_loss: 1.8053 - val_accuracy: 0.4119 - lr: 1.0000e-04\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.4054 - accuracy: 0.9270 - val_loss: 1.7849 - val_accuracy: 0.4179 - lr: 1.0000e-04\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.4055 - accuracy: 0.9276 - val_loss: 1.7610 - val_accuracy: 0.4202 - lr: 1.0000e-04\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.3920 - accuracy: 0.9214 - val_loss: 1.7422 - val_accuracy: 0.4250 - lr: 1.0000e-04\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.3936 - accuracy: 0.9230 - val_loss: 1.7248 - val_accuracy: 0.4357 - lr: 1.0000e-04\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 0.4035 - accuracy: 0.9260 - val_loss: 1.7062 - val_accuracy: 0.4417 - lr: 1.0000e-04\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.3799 - accuracy: 0.9311 - val_loss: 1.6879 - val_accuracy: 0.4452 - lr: 1.0000e-04\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.3792 - accuracy: 0.9321 - val_loss: 1.6691 - val_accuracy: 0.4536 - lr: 1.0000e-04\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.4053 - accuracy: 0.9189 - val_loss: 1.6538 - val_accuracy: 0.4583 - lr: 1.0000e-04\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.3775 - accuracy: 0.9311 - val_loss: 1.6386 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.3623 - accuracy: 0.9311 - val_loss: 1.6261 - val_accuracy: 0.4726 - lr: 1.0000e-04\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.3745 - accuracy: 0.9230 - val_loss: 1.6165 - val_accuracy: 0.4810 - lr: 1.0000e-04\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.3563 - accuracy: 0.9352 - val_loss: 1.6058 - val_accuracy: 0.4821 - lr: 1.0000e-04\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.3585 - accuracy: 0.9327 - val_loss: 1.5965 - val_accuracy: 0.4857 - lr: 1.0000e-04\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.3609 - accuracy: 0.9286 - val_loss: 1.5839 - val_accuracy: 0.4881 - lr: 1.0000e-04\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.3430 - accuracy: 0.9408 - val_loss: 1.5686 - val_accuracy: 0.5012 - lr: 1.0000e-04\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 0.3509 - accuracy: 0.9352 - val_loss: 1.5496 - val_accuracy: 0.5083 - lr: 1.0000e-04\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.3416 - accuracy: 0.9398 - val_loss: 1.5312 - val_accuracy: 0.5143 - lr: 1.0000e-04\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.3486 - accuracy: 0.9388 - val_loss: 1.5142 - val_accuracy: 0.5250 - lr: 1.0000e-04\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.3357 - accuracy: 0.9444 - val_loss: 1.5000 - val_accuracy: 0.5298 - lr: 1.0000e-04\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.3307 - accuracy: 0.9408 - val_loss: 1.4869 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.3394 - accuracy: 0.9383 - val_loss: 1.4755 - val_accuracy: 0.5393 - lr: 1.0000e-04\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.3207 - accuracy: 0.9434 - val_loss: 1.4652 - val_accuracy: 0.5452 - lr: 1.0000e-04\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.3109 - accuracy: 0.9505 - val_loss: 1.4554 - val_accuracy: 0.5524 - lr: 1.0000e-04\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.3293 - accuracy: 0.9352 - val_loss: 1.4453 - val_accuracy: 0.5595 - lr: 1.0000e-04\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.3051 - accuracy: 0.9536 - val_loss: 1.4342 - val_accuracy: 0.5655 - lr: 1.0000e-04\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.3024 - accuracy: 0.9500 - val_loss: 1.4243 - val_accuracy: 0.5690 - lr: 1.0000e-04\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.3099 - accuracy: 0.9464 - val_loss: 1.4106 - val_accuracy: 0.5726 - lr: 1.0000e-04\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.3012 - accuracy: 0.9480 - val_loss: 1.3979 - val_accuracy: 0.5798 - lr: 1.0000e-04\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.3078 - accuracy: 0.9434 - val_loss: 1.3863 - val_accuracy: 0.5857 - lr: 1.0000e-04\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.2997 - accuracy: 0.9505 - val_loss: 1.3755 - val_accuracy: 0.5881 - lr: 1.0000e-04\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.2843 - accuracy: 0.9556 - val_loss: 1.3626 - val_accuracy: 0.5940 - lr: 1.0000e-04\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.2925 - accuracy: 0.9480 - val_loss: 1.3514 - val_accuracy: 0.5976 - lr: 1.0000e-04\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.2830 - accuracy: 0.9500 - val_loss: 1.3371 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.2817 - accuracy: 0.9587 - val_loss: 1.3250 - val_accuracy: 0.6024 - lr: 1.0000e-04\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.2696 - accuracy: 0.9571 - val_loss: 1.3108 - val_accuracy: 0.6060 - lr: 1.0000e-04\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.2804 - accuracy: 0.9505 - val_loss: 1.2978 - val_accuracy: 0.6095 - lr: 1.0000e-04\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.2712 - accuracy: 0.9577 - val_loss: 1.2874 - val_accuracy: 0.6095 - lr: 1.0000e-04\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.2849 - accuracy: 0.9500 - val_loss: 1.2743 - val_accuracy: 0.6119 - lr: 1.0000e-04\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.2667 - accuracy: 0.9628 - val_loss: 1.2626 - val_accuracy: 0.6131 - lr: 1.0000e-04\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.2767 - accuracy: 0.9592 - val_loss: 1.2516 - val_accuracy: 0.6179 - lr: 1.0000e-04\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.2628 - accuracy: 0.9628 - val_loss: 1.2405 - val_accuracy: 0.6190 - lr: 1.0000e-04\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.2702 - accuracy: 0.9597 - val_loss: 1.2290 - val_accuracy: 0.6226 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.2643 - accuracy: 0.9556 - val_loss: 1.2161 - val_accuracy: 0.6262 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.2628 - accuracy: 0.9617 - val_loss: 1.2000 - val_accuracy: 0.6321 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.2348 - accuracy: 0.9679 - val_loss: 1.1849 - val_accuracy: 0.6417 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.2544 - accuracy: 0.9602 - val_loss: 1.1709 - val_accuracy: 0.6488 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.2557 - accuracy: 0.9607 - val_loss: 1.1582 - val_accuracy: 0.6476 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.2381 - accuracy: 0.9673 - val_loss: 1.1469 - val_accuracy: 0.6488 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.2581 - accuracy: 0.9556 - val_loss: 1.1402 - val_accuracy: 0.6560 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.2466 - accuracy: 0.9653 - val_loss: 1.1324 - val_accuracy: 0.6595 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.2418 - accuracy: 0.9643 - val_loss: 1.1239 - val_accuracy: 0.6607 - lr: 5.0000e-05\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.2375 - accuracy: 0.9668 - val_loss: 1.1145 - val_accuracy: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.2353 - accuracy: 0.9714 - val_loss: 1.1043 - val_accuracy: 0.6714 - lr: 5.0000e-05\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.2366 - accuracy: 0.9633 - val_loss: 1.0943 - val_accuracy: 0.6738 - lr: 5.0000e-05\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.2295 - accuracy: 0.9709 - val_loss: 1.0838 - val_accuracy: 0.6774 - lr: 5.0000e-05\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.2262 - accuracy: 0.9704 - val_loss: 1.0726 - val_accuracy: 0.6857 - lr: 5.0000e-05\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 0.2367 - accuracy: 0.9633 - val_loss: 1.0603 - val_accuracy: 0.6893 - lr: 5.0000e-05\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.2374 - accuracy: 0.9663 - val_loss: 1.0470 - val_accuracy: 0.6952 - lr: 5.0000e-05\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.2378 - accuracy: 0.9709 - val_loss: 1.0354 - val_accuracy: 0.7012 - lr: 5.0000e-05\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.2239 - accuracy: 0.9740 - val_loss: 1.0241 - val_accuracy: 0.7024 - lr: 5.0000e-05\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.2289 - accuracy: 0.9704 - val_loss: 1.0127 - val_accuracy: 0.7083 - lr: 5.0000e-05\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 0.2276 - accuracy: 0.9684 - val_loss: 1.0020 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.2342 - accuracy: 0.9679 - val_loss: 0.9914 - val_accuracy: 0.7167 - lr: 5.0000e-05\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.2257 - accuracy: 0.9668 - val_loss: 0.9794 - val_accuracy: 0.7226 - lr: 5.0000e-05\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.2368 - accuracy: 0.9643 - val_loss: 0.9687 - val_accuracy: 0.7238 - lr: 5.0000e-05\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.2264 - accuracy: 0.9668 - val_loss: 0.9606 - val_accuracy: 0.7274 - lr: 2.5000e-05\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.2289 - accuracy: 0.9724 - val_loss: 0.9523 - val_accuracy: 0.7274 - lr: 2.5000e-05\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.2160 - accuracy: 0.9791 - val_loss: 0.9445 - val_accuracy: 0.7298 - lr: 2.5000e-05\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.2241 - accuracy: 0.9719 - val_loss: 0.9370 - val_accuracy: 0.7333 - lr: 2.5000e-05\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.2312 - accuracy: 0.9658 - val_loss: 0.9297 - val_accuracy: 0.7381 - lr: 2.5000e-05\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.2246 - accuracy: 0.9694 - val_loss: 0.9228 - val_accuracy: 0.7393 - lr: 2.5000e-05\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.2252 - accuracy: 0.9709 - val_loss: 0.9155 - val_accuracy: 0.7405 - lr: 2.5000e-05\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.2159 - accuracy: 0.9735 - val_loss: 0.9086 - val_accuracy: 0.7417 - lr: 2.5000e-05\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.2178 - accuracy: 0.9699 - val_loss: 0.9025 - val_accuracy: 0.7417 - lr: 2.5000e-05\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.2140 - accuracy: 0.9694 - val_loss: 0.8960 - val_accuracy: 0.7452 - lr: 2.5000e-05\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.2193 - accuracy: 0.9730 - val_loss: 0.8894 - val_accuracy: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 0.2278 - accuracy: 0.9648 - val_loss: 0.8823 - val_accuracy: 0.7500 - lr: 2.5000e-05\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.2222 - accuracy: 0.9679 - val_loss: 0.8753 - val_accuracy: 0.7512 - lr: 2.5000e-05\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.2163 - accuracy: 0.9724 - val_loss: 0.8686 - val_accuracy: 0.7524 - lr: 2.5000e-05\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.1961 - accuracy: 0.9750 - val_loss: 0.8622 - val_accuracy: 0.7524 - lr: 2.5000e-05\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.2280 - accuracy: 0.9638 - val_loss: 0.8556 - val_accuracy: 0.7536 - lr: 2.5000e-05\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.2155 - accuracy: 0.9694 - val_loss: 0.8483 - val_accuracy: 0.7548 - lr: 2.5000e-05\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.2155 - accuracy: 0.9673 - val_loss: 0.8408 - val_accuracy: 0.7583 - lr: 2.5000e-05\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.2186 - accuracy: 0.9684 - val_loss: 0.8332 - val_accuracy: 0.7583 - lr: 2.5000e-05\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.2205 - accuracy: 0.9735 - val_loss: 0.8258 - val_accuracy: 0.7607 - lr: 2.5000e-05\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.2111 - accuracy: 0.9699 - val_loss: 0.8186 - val_accuracy: 0.7619 - lr: 1.2500e-05\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.2094 - accuracy: 0.9714 - val_loss: 0.8116 - val_accuracy: 0.7643 - lr: 1.2500e-05\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.2043 - accuracy: 0.9719 - val_loss: 0.8045 - val_accuracy: 0.7679 - lr: 1.2500e-05\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.2110 - accuracy: 0.9735 - val_loss: 0.7975 - val_accuracy: 0.7690 - lr: 1.2500e-05\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.2096 - accuracy: 0.9765 - val_loss: 0.7907 - val_accuracy: 0.7714 - lr: 1.2500e-05\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.2104 - accuracy: 0.9750 - val_loss: 0.7841 - val_accuracy: 0.7726 - lr: 1.2500e-05\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.2164 - accuracy: 0.9699 - val_loss: 0.7778 - val_accuracy: 0.7750 - lr: 1.2500e-05\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.2169 - accuracy: 0.9663 - val_loss: 0.7712 - val_accuracy: 0.7762 - lr: 1.2500e-05\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.2242 - accuracy: 0.9689 - val_loss: 0.7644 - val_accuracy: 0.7798 - lr: 1.2500e-05\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.2178 - accuracy: 0.9719 - val_loss: 0.7579 - val_accuracy: 0.7798 - lr: 6.2500e-06\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.2193 - accuracy: 0.9709 - val_loss: 0.7516 - val_accuracy: 0.7798 - lr: 6.2500e-06\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 0.2120 - accuracy: 0.9786 - val_loss: 0.7452 - val_accuracy: 0.7821 - lr: 6.2500e-06\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.1972 - accuracy: 0.9796 - val_loss: 0.7387 - val_accuracy: 0.7833 - lr: 6.2500e-06\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.2098 - accuracy: 0.9760 - val_loss: 0.7322 - val_accuracy: 0.7845 - lr: 6.2500e-06\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.2046 - accuracy: 0.9714 - val_loss: 0.7260 - val_accuracy: 0.7869 - lr: 6.2500e-06\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.2060 - accuracy: 0.9730 - val_loss: 0.7198 - val_accuracy: 0.7881 - lr: 6.2500e-06\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.2247 - accuracy: 0.9714 - val_loss: 0.7136 - val_accuracy: 0.7893 - lr: 6.2500e-06\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.2085 - accuracy: 0.9719 - val_loss: 0.7073 - val_accuracy: 0.7905 - lr: 6.2500e-06\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.2087 - accuracy: 0.9745 - val_loss: 0.7011 - val_accuracy: 0.7905 - lr: 5.0000e-06\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.1959 - accuracy: 0.9801 - val_loss: 0.6950 - val_accuracy: 0.7940 - lr: 5.0000e-06\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.2121 - accuracy: 0.9740 - val_loss: 0.6892 - val_accuracy: 0.7952 - lr: 5.0000e-06\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.2041 - accuracy: 0.9740 - val_loss: 0.6834 - val_accuracy: 0.7988 - lr: 5.0000e-06\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.2125 - accuracy: 0.9699 - val_loss: 0.6777 - val_accuracy: 0.8012 - lr: 5.0000e-06\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.2172 - accuracy: 0.9750 - val_loss: 0.6719 - val_accuracy: 0.8036 - lr: 5.0000e-06\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.2123 - accuracy: 0.9730 - val_loss: 0.6663 - val_accuracy: 0.8036 - lr: 5.0000e-06\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.2123 - accuracy: 0.9735 - val_loss: 0.6608 - val_accuracy: 0.8048 - lr: 5.0000e-06\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.2147 - accuracy: 0.9730 - val_loss: 0.6553 - val_accuracy: 0.8095 - lr: 5.0000e-06\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.2223 - accuracy: 0.9684 - val_loss: 0.6499 - val_accuracy: 0.8131 - lr: 5.0000e-06\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.2207 - accuracy: 0.9714 - val_loss: 0.6445 - val_accuracy: 0.8155 - lr: 5.0000e-06\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.2141 - accuracy: 0.9724 - val_loss: 0.6394 - val_accuracy: 0.8167 - lr: 5.0000e-06\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.2062 - accuracy: 0.9755 - val_loss: 0.6343 - val_accuracy: 0.8190 - lr: 5.0000e-06\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.2134 - accuracy: 0.9694 - val_loss: 0.6293 - val_accuracy: 0.8190 - lr: 5.0000e-06\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.2019 - accuracy: 0.9760 - val_loss: 0.6243 - val_accuracy: 0.8202 - lr: 5.0000e-06\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.2138 - accuracy: 0.9699 - val_loss: 0.6193 - val_accuracy: 0.8202 - lr: 5.0000e-06\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.1991 - accuracy: 0.9750 - val_loss: 0.6145 - val_accuracy: 0.8226 - lr: 5.0000e-06\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.2149 - accuracy: 0.9668 - val_loss: 0.6098 - val_accuracy: 0.8238 - lr: 5.0000e-06\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.2180 - accuracy: 0.9714 - val_loss: 0.6050 - val_accuracy: 0.8250 - lr: 5.0000e-06\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.2146 - accuracy: 0.9714 - val_loss: 0.6002 - val_accuracy: 0.8250 - lr: 5.0000e-06\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.2258 - accuracy: 0.9694 - val_loss: 0.5956 - val_accuracy: 0.8274 - lr: 5.0000e-06\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.2100 - accuracy: 0.9730 - val_loss: 0.5910 - val_accuracy: 0.8274 - lr: 5.0000e-06\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.2060 - accuracy: 0.9730 - val_loss: 0.5865 - val_accuracy: 0.8274 - lr: 5.0000e-06\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.2090 - accuracy: 0.9694 - val_loss: 0.5819 - val_accuracy: 0.8298 - lr: 5.0000e-06\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.2091 - accuracy: 0.9689 - val_loss: 0.5775 - val_accuracy: 0.8310 - lr: 5.0000e-06\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.2191 - accuracy: 0.9622 - val_loss: 0.5732 - val_accuracy: 0.8310 - lr: 5.0000e-06\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.2019 - accuracy: 0.9755 - val_loss: 0.5687 - val_accuracy: 0.8321 - lr: 5.0000e-06\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.2196 - accuracy: 0.9755 - val_loss: 0.5644 - val_accuracy: 0.8321 - lr: 5.0000e-06\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.2156 - accuracy: 0.9730 - val_loss: 0.5602 - val_accuracy: 0.8333 - lr: 5.0000e-06\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.2064 - accuracy: 0.9740 - val_loss: 0.5562 - val_accuracy: 0.8345 - lr: 5.0000e-06\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.2104 - accuracy: 0.9709 - val_loss: 0.5522 - val_accuracy: 0.8369 - lr: 5.0000e-06\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.2000 - accuracy: 0.9745 - val_loss: 0.5481 - val_accuracy: 0.8381 - lr: 5.0000e-06\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 0.2042 - accuracy: 0.9735 - val_loss: 0.5442 - val_accuracy: 0.8405 - lr: 5.0000e-06\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.2052 - accuracy: 0.9750 - val_loss: 0.5403 - val_accuracy: 0.8405 - lr: 5.0000e-06\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.2179 - accuracy: 0.9745 - val_loss: 0.5365 - val_accuracy: 0.8405 - lr: 5.0000e-06\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.2116 - accuracy: 0.9740 - val_loss: 0.5327 - val_accuracy: 0.8405 - lr: 5.0000e-06\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.2047 - accuracy: 0.9745 - val_loss: 0.5291 - val_accuracy: 0.8429 - lr: 5.0000e-06\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.2165 - accuracy: 0.9617 - val_loss: 0.5254 - val_accuracy: 0.8452 - lr: 5.0000e-06\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.2090 - accuracy: 0.9755 - val_loss: 0.5217 - val_accuracy: 0.8464 - lr: 5.0000e-06\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.2016 - accuracy: 0.9740 - val_loss: 0.5179 - val_accuracy: 0.8464 - lr: 5.0000e-06\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.2154 - accuracy: 0.9694 - val_loss: 0.5141 - val_accuracy: 0.8500 - lr: 5.0000e-06\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.2084 - accuracy: 0.9709 - val_loss: 0.5104 - val_accuracy: 0.8500 - lr: 5.0000e-06\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.2131 - accuracy: 0.9709 - val_loss: 0.5064 - val_accuracy: 0.8512 - lr: 5.0000e-06\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.2073 - accuracy: 0.9750 - val_loss: 0.5026 - val_accuracy: 0.8536 - lr: 5.0000e-06\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.2052 - accuracy: 0.9724 - val_loss: 0.4988 - val_accuracy: 0.8548 - lr: 5.0000e-06\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.2016 - accuracy: 0.9719 - val_loss: 0.4951 - val_accuracy: 0.8560 - lr: 5.0000e-06\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.2001 - accuracy: 0.9745 - val_loss: 0.4914 - val_accuracy: 0.8571 - lr: 5.0000e-06\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.2033 - accuracy: 0.9714 - val_loss: 0.4879 - val_accuracy: 0.8571 - lr: 5.0000e-06\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.2080 - accuracy: 0.9699 - val_loss: 0.4843 - val_accuracy: 0.8595 - lr: 5.0000e-06\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.1988 - accuracy: 0.9714 - val_loss: 0.4808 - val_accuracy: 0.8607 - lr: 5.0000e-06\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 0.2103 - accuracy: 0.9730 - val_loss: 0.4774 - val_accuracy: 0.8655 - lr: 5.0000e-06\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.1963 - accuracy: 0.9750 - val_loss: 0.4740 - val_accuracy: 0.8655 - lr: 5.0000e-06\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.2014 - accuracy: 0.9760 - val_loss: 0.4706 - val_accuracy: 0.8667 - lr: 5.0000e-06\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.2150 - accuracy: 0.9694 - val_loss: 0.4673 - val_accuracy: 0.8667 - lr: 5.0000e-06\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.2049 - accuracy: 0.9770 - val_loss: 0.4640 - val_accuracy: 0.8667 - lr: 5.0000e-06\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.2020 - accuracy: 0.9745 - val_loss: 0.4607 - val_accuracy: 0.8690 - lr: 5.0000e-06\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.1986 - accuracy: 0.9755 - val_loss: 0.4575 - val_accuracy: 0.8702 - lr: 5.0000e-06\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 0.2156 - accuracy: 0.9684 - val_loss: 0.4545 - val_accuracy: 0.8714 - lr: 5.0000e-06\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.2068 - accuracy: 0.9770 - val_loss: 0.4514 - val_accuracy: 0.8714 - lr: 5.0000e-06\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.2078 - accuracy: 0.9724 - val_loss: 0.4485 - val_accuracy: 0.8726 - lr: 5.0000e-06\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.2073 - accuracy: 0.9750 - val_loss: 0.4455 - val_accuracy: 0.8750 - lr: 5.0000e-06\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.2087 - accuracy: 0.9709 - val_loss: 0.4425 - val_accuracy: 0.8750 - lr: 5.0000e-06\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.1948 - accuracy: 0.9765 - val_loss: 0.4396 - val_accuracy: 0.8810 - lr: 5.0000e-06\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 0.2016 - accuracy: 0.9755 - val_loss: 0.4366 - val_accuracy: 0.8821 - lr: 5.0000e-06\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.2080 - accuracy: 0.9750 - val_loss: 0.4337 - val_accuracy: 0.8845 - lr: 5.0000e-06\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.2061 - accuracy: 0.9755 - val_loss: 0.4309 - val_accuracy: 0.8857 - lr: 5.0000e-06\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.1947 - accuracy: 0.9745 - val_loss: 0.4280 - val_accuracy: 0.8881 - lr: 5.0000e-06\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.1999 - accuracy: 0.9750 - val_loss: 0.4253 - val_accuracy: 0.8881 - lr: 5.0000e-06\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.2091 - accuracy: 0.9684 - val_loss: 0.4224 - val_accuracy: 0.8881 - lr: 5.0000e-06\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.2024 - accuracy: 0.9740 - val_loss: 0.4197 - val_accuracy: 0.8881 - lr: 5.0000e-06\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.2009 - accuracy: 0.9735 - val_loss: 0.4170 - val_accuracy: 0.8881 - lr: 5.0000e-06\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.1968 - accuracy: 0.9776 - val_loss: 0.4142 - val_accuracy: 0.8893 - lr: 5.0000e-06\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.2010 - accuracy: 0.9755 - val_loss: 0.4115 - val_accuracy: 0.8893 - lr: 5.0000e-06\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.2008 - accuracy: 0.9735 - val_loss: 0.4089 - val_accuracy: 0.8905 - lr: 5.0000e-06\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.2023 - accuracy: 0.9760 - val_loss: 0.4063 - val_accuracy: 0.8905 - lr: 5.0000e-06\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.2001 - accuracy: 0.9791 - val_loss: 0.4037 - val_accuracy: 0.8905 - lr: 5.0000e-06\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.2026 - accuracy: 0.9755 - val_loss: 0.4011 - val_accuracy: 0.8905 - lr: 5.0000e-06\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.2079 - accuracy: 0.9750 - val_loss: 0.3987 - val_accuracy: 0.8905 - lr: 5.0000e-06\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 0.2056 - accuracy: 0.9719 - val_loss: 0.3963 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.2088 - accuracy: 0.9745 - val_loss: 0.3940 - val_accuracy: 0.8940 - lr: 5.0000e-06\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.2097 - accuracy: 0.9709 - val_loss: 0.3916 - val_accuracy: 0.8940 - lr: 5.0000e-06\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.2014 - accuracy: 0.9745 - val_loss: 0.3891 - val_accuracy: 0.8940 - lr: 5.0000e-06\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.2016 - accuracy: 0.9786 - val_loss: 0.3867 - val_accuracy: 0.8952 - lr: 5.0000e-06\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.2190 - accuracy: 0.9679 - val_loss: 0.3842 - val_accuracy: 0.8964 - lr: 5.0000e-06\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.2005 - accuracy: 0.9765 - val_loss: 0.3818 - val_accuracy: 0.8964 - lr: 5.0000e-06\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.2028 - accuracy: 0.9730 - val_loss: 0.3793 - val_accuracy: 0.8976 - lr: 5.0000e-06\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.2060 - accuracy: 0.9770 - val_loss: 0.3769 - val_accuracy: 0.8988 - lr: 5.0000e-06\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.2072 - accuracy: 0.9760 - val_loss: 0.3745 - val_accuracy: 0.8988 - lr: 5.0000e-06\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.2059 - accuracy: 0.9689 - val_loss: 0.3722 - val_accuracy: 0.8988 - lr: 5.0000e-06\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.2040 - accuracy: 0.9735 - val_loss: 0.3699 - val_accuracy: 0.9012 - lr: 5.0000e-06\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.2053 - accuracy: 0.9714 - val_loss: 0.3676 - val_accuracy: 0.9012 - lr: 5.0000e-06\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.2071 - accuracy: 0.9719 - val_loss: 0.3653 - val_accuracy: 0.9012 - lr: 5.0000e-06\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.2068 - accuracy: 0.9740 - val_loss: 0.3630 - val_accuracy: 0.9012 - lr: 5.0000e-06\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.2021 - accuracy: 0.9755 - val_loss: 0.3608 - val_accuracy: 0.9024 - lr: 5.0000e-06\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.2049 - accuracy: 0.9735 - val_loss: 0.3586 - val_accuracy: 0.9048 - lr: 5.0000e-06\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.2108 - accuracy: 0.9694 - val_loss: 0.3564 - val_accuracy: 0.9071 - lr: 5.0000e-06\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 0.2071 - accuracy: 0.9745 - val_loss: 0.3543 - val_accuracy: 0.9083 - lr: 5.0000e-06\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.2026 - accuracy: 0.9750 - val_loss: 0.3522 - val_accuracy: 0.9083 - lr: 5.0000e-06\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.2156 - accuracy: 0.9699 - val_loss: 0.3501 - val_accuracy: 0.9083 - lr: 5.0000e-06\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.1904 - accuracy: 0.9776 - val_loss: 0.3480 - val_accuracy: 0.9083 - lr: 5.0000e-06\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.1951 - accuracy: 0.9806 - val_loss: 0.3460 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.2080 - accuracy: 0.9699 - val_loss: 0.3440 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.2031 - accuracy: 0.9750 - val_loss: 0.3422 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.2052 - accuracy: 0.9709 - val_loss: 0.3404 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.1890 - accuracy: 0.9801 - val_loss: 0.3385 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.1938 - accuracy: 0.9801 - val_loss: 0.3368 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.1900 - accuracy: 0.9770 - val_loss: 0.3351 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.1939 - accuracy: 0.9755 - val_loss: 0.3335 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.1989 - accuracy: 0.9786 - val_loss: 0.3318 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.2054 - accuracy: 0.9735 - val_loss: 0.3301 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.1970 - accuracy: 0.9750 - val_loss: 0.3285 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 0.2002 - accuracy: 0.9714 - val_loss: 0.3269 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.2136 - accuracy: 0.9730 - val_loss: 0.3253 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 0.1970 - accuracy: 0.9765 - val_loss: 0.3238 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.2142 - accuracy: 0.9694 - val_loss: 0.3223 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.2016 - accuracy: 0.9745 - val_loss: 0.3208 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.1980 - accuracy: 0.9730 - val_loss: 0.3192 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 384ms/step - loss: 0.2017 - accuracy: 0.9740 - val_loss: 0.3176 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.2028 - accuracy: 0.9699 - val_loss: 0.3160 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 0.1897 - accuracy: 0.9770 - val_loss: 0.3144 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.2050 - accuracy: 0.9724 - val_loss: 0.3129 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.1916 - accuracy: 0.9724 - val_loss: 0.3114 - val_accuracy: 0.9119 - lr: 5.0000e-06\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.2058 - accuracy: 0.9745 - val_loss: 0.3098 - val_accuracy: 0.9119 - lr: 5.0000e-06\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.1907 - accuracy: 0.9791 - val_loss: 0.3082 - val_accuracy: 0.9131 - lr: 5.0000e-06\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.2099 - accuracy: 0.9719 - val_loss: 0.3067 - val_accuracy: 0.9131 - lr: 5.0000e-06\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.1974 - accuracy: 0.9735 - val_loss: 0.3053 - val_accuracy: 0.9131 - lr: 5.0000e-06\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.2008 - accuracy: 0.9730 - val_loss: 0.3038 - val_accuracy: 0.9143 - lr: 5.0000e-06\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.1969 - accuracy: 0.9724 - val_loss: 0.3023 - val_accuracy: 0.9143 - lr: 5.0000e-06\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.1976 - accuracy: 0.9714 - val_loss: 0.3009 - val_accuracy: 0.9155 - lr: 5.0000e-06\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 278ms/step - loss: 0.2034 - accuracy: 0.9694 - val_loss: 0.2995 - val_accuracy: 0.9155 - lr: 5.0000e-06\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.2023 - accuracy: 0.9740 - val_loss: 0.2982 - val_accuracy: 0.9167 - lr: 5.0000e-06\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.1996 - accuracy: 0.9745 - val_loss: 0.2969 - val_accuracy: 0.9167 - lr: 5.0000e-06\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.2002 - accuracy: 0.9745 - val_loss: 0.2956 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.2105 - accuracy: 0.9719 - val_loss: 0.2944 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.2026 - accuracy: 0.9714 - val_loss: 0.2930 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.1848 - accuracy: 0.9776 - val_loss: 0.2917 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.1929 - accuracy: 0.9791 - val_loss: 0.2905 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.1995 - accuracy: 0.9740 - val_loss: 0.2893 - val_accuracy: 0.9214 - lr: 5.0000e-06\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 0.1989 - accuracy: 0.9776 - val_loss: 0.2881 - val_accuracy: 0.9214 - lr: 5.0000e-06\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1917 - accuracy: 0.9755 - val_loss: 0.2869 - val_accuracy: 0.9214 - lr: 5.0000e-06\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 296ms/step - loss: 0.1906 - accuracy: 0.9801 - val_loss: 0.2859 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.1907 - accuracy: 0.9776 - val_loss: 0.2847 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.2023 - accuracy: 0.9740 - val_loss: 0.2836 - val_accuracy: 0.9238 - lr: 5.0000e-06\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.1872 - accuracy: 0.9750 - val_loss: 0.2824 - val_accuracy: 0.9238 - lr: 5.0000e-06\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.1959 - accuracy: 0.9776 - val_loss: 0.2813 - val_accuracy: 0.9238 - lr: 5.0000e-06\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.1972 - accuracy: 0.9750 - val_loss: 0.2803 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.1924 - accuracy: 0.9740 - val_loss: 0.2792 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.1911 - accuracy: 0.9770 - val_loss: 0.2782 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.1954 - accuracy: 0.9760 - val_loss: 0.2771 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.1989 - accuracy: 0.9760 - val_loss: 0.2761 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.1966 - accuracy: 0.9735 - val_loss: 0.2751 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.1792 - accuracy: 0.9806 - val_loss: 0.2740 - val_accuracy: 0.9262 - lr: 5.0000e-06\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.1984 - accuracy: 0.9770 - val_loss: 0.2730 - val_accuracy: 0.9274 - lr: 5.0000e-06\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.2021 - accuracy: 0.9740 - val_loss: 0.2720 - val_accuracy: 0.9274 - lr: 5.0000e-06\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.2069 - accuracy: 0.9760 - val_loss: 0.2711 - val_accuracy: 0.9274 - lr: 5.0000e-06\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.2010 - accuracy: 0.9770 - val_loss: 0.2701 - val_accuracy: 0.9274 - lr: 5.0000e-06\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.1984 - accuracy: 0.9740 - val_loss: 0.2692 - val_accuracy: 0.9274 - lr: 5.0000e-06\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.1918 - accuracy: 0.9770 - val_loss: 0.2682 - val_accuracy: 0.9274 - lr: 5.0000e-06\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 0.2042 - accuracy: 0.9719 - val_loss: 0.2673 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.1819 - accuracy: 0.9781 - val_loss: 0.2664 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.2037 - accuracy: 0.9760 - val_loss: 0.2656 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 0.1940 - accuracy: 0.9755 - val_loss: 0.2647 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1992 - accuracy: 0.9745 - val_loss: 0.2639 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.1909 - accuracy: 0.9781 - val_loss: 0.2631 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 0.2002 - accuracy: 0.9735 - val_loss: 0.2623 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.1829 - accuracy: 0.9765 - val_loss: 0.2615 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.2007 - accuracy: 0.9704 - val_loss: 0.2607 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.2004 - accuracy: 0.9765 - val_loss: 0.2598 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 288ms/step - loss: 0.1999 - accuracy: 0.9755 - val_loss: 0.2591 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.1770 - accuracy: 0.9857 - val_loss: 0.2583 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.1934 - accuracy: 0.9760 - val_loss: 0.2575 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.1939 - accuracy: 0.9791 - val_loss: 0.2567 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 0.1973 - accuracy: 0.9765 - val_loss: 0.2560 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.2009 - accuracy: 0.9719 - val_loss: 0.2552 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.2020 - accuracy: 0.9735 - val_loss: 0.2544 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1902 - accuracy: 0.9760 - val_loss: 0.2537 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.1928 - accuracy: 0.9755 - val_loss: 0.2530 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.1967 - accuracy: 0.9740 - val_loss: 0.2523 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1927 - accuracy: 0.9755 - val_loss: 0.2516 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.1879 - accuracy: 0.9816 - val_loss: 0.2510 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.1953 - accuracy: 0.9719 - val_loss: 0.2503 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 0.1885 - accuracy: 0.9776 - val_loss: 0.2497 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1987 - accuracy: 0.9796 - val_loss: 0.2491 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.2064 - accuracy: 0.9673 - val_loss: 0.2484 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 0.1828 - accuracy: 0.9811 - val_loss: 0.2477 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.1863 - accuracy: 0.9781 - val_loss: 0.2470 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1977 - accuracy: 0.9765 - val_loss: 0.2464 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.1858 - accuracy: 0.9781 - val_loss: 0.2458 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1997 - accuracy: 0.9694 - val_loss: 0.2452 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.2064 - accuracy: 0.9755 - val_loss: 0.2445 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.1958 - accuracy: 0.9765 - val_loss: 0.2439 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.2004 - accuracy: 0.9735 - val_loss: 0.2433 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.1966 - accuracy: 0.9765 - val_loss: 0.2427 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.1933 - accuracy: 0.9735 - val_loss: 0.2420 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.2035 - accuracy: 0.9719 - val_loss: 0.2414 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.2008 - accuracy: 0.9663 - val_loss: 0.2408 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 0.1915 - accuracy: 0.9730 - val_loss: 0.2402 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1919 - accuracy: 0.9811 - val_loss: 0.2397 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.1875 - accuracy: 0.9776 - val_loss: 0.2390 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.1921 - accuracy: 0.9786 - val_loss: 0.2384 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.1963 - accuracy: 0.9770 - val_loss: 0.2379 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.1939 - accuracy: 0.9755 - val_loss: 0.2373 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.1925 - accuracy: 0.9760 - val_loss: 0.2367 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.1974 - accuracy: 0.9760 - val_loss: 0.2362 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.1837 - accuracy: 0.9806 - val_loss: 0.2356 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.1895 - accuracy: 0.9735 - val_loss: 0.2351 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.1864 - accuracy: 0.9801 - val_loss: 0.2345 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.2032 - accuracy: 0.9730 - val_loss: 0.2340 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.1905 - accuracy: 0.9781 - val_loss: 0.2335 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.1864 - accuracy: 0.9765 - val_loss: 0.2331 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.1898 - accuracy: 0.9735 - val_loss: 0.2326 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.1877 - accuracy: 0.9776 - val_loss: 0.2321 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.2037 - accuracy: 0.9689 - val_loss: 0.2316 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.1895 - accuracy: 0.9760 - val_loss: 0.2311 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.1932 - accuracy: 0.9740 - val_loss: 0.2306 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.1958 - accuracy: 0.9765 - val_loss: 0.2302 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 309ms/step - loss: 0.1899 - accuracy: 0.9765 - val_loss: 0.2297 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.1946 - accuracy: 0.9745 - val_loss: 0.2292 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 285ms/step - loss: 0.1863 - accuracy: 0.9791 - val_loss: 0.2288 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1847 - accuracy: 0.9765 - val_loss: 0.2284 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 0.1854 - accuracy: 0.9791 - val_loss: 0.2279 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.1961 - accuracy: 0.9719 - val_loss: 0.2275 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.1936 - accuracy: 0.9724 - val_loss: 0.2270 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.2017 - accuracy: 0.9694 - val_loss: 0.2265 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1825 - accuracy: 0.9776 - val_loss: 0.2260 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.1861 - accuracy: 0.9750 - val_loss: 0.2255 - val_accuracy: 0.9369 - lr: 5.0000e-06\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.1935 - accuracy: 0.9724 - val_loss: 0.2250 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.1830 - accuracy: 0.9770 - val_loss: 0.2245 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.1974 - accuracy: 0.9750 - val_loss: 0.2240 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.1863 - accuracy: 0.9791 - val_loss: 0.2236 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.1824 - accuracy: 0.9781 - val_loss: 0.2232 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.1971 - accuracy: 0.9740 - val_loss: 0.2228 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.2014 - accuracy: 0.9730 - val_loss: 0.2224 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.1961 - accuracy: 0.9745 - val_loss: 0.2220 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.1896 - accuracy: 0.9745 - val_loss: 0.2217 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.1956 - accuracy: 0.9776 - val_loss: 0.2213 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 0.1873 - accuracy: 0.9770 - val_loss: 0.2210 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.2041 - accuracy: 0.9765 - val_loss: 0.2207 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1878 - accuracy: 0.9796 - val_loss: 0.2204 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 0.1925 - accuracy: 0.9791 - val_loss: 0.2201 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.1924 - accuracy: 0.9714 - val_loss: 0.2198 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 370ms/step - loss: 0.1972 - accuracy: 0.9714 - val_loss: 0.2195 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.1950 - accuracy: 0.9745 - val_loss: 0.2192 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.1965 - accuracy: 0.9709 - val_loss: 0.2189 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.1944 - accuracy: 0.9719 - val_loss: 0.2187 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1803 - accuracy: 0.9811 - val_loss: 0.2184 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.1981 - accuracy: 0.9745 - val_loss: 0.2181 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.1850 - accuracy: 0.9770 - val_loss: 0.2179 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.1837 - accuracy: 0.9765 - val_loss: 0.2176 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.1960 - accuracy: 0.9724 - val_loss: 0.2173 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.1908 - accuracy: 0.9765 - val_loss: 0.2171 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.1914 - accuracy: 0.9730 - val_loss: 0.2168 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.1808 - accuracy: 0.9816 - val_loss: 0.2166 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.1867 - accuracy: 0.9735 - val_loss: 0.2163 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.1956 - accuracy: 0.9755 - val_loss: 0.2161 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.1909 - accuracy: 0.9699 - val_loss: 0.2159 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.1848 - accuracy: 0.9801 - val_loss: 0.2156 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.1841 - accuracy: 0.9796 - val_loss: 0.2154 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.1948 - accuracy: 0.9740 - val_loss: 0.2152 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.1880 - accuracy: 0.9760 - val_loss: 0.2151 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1896 - accuracy: 0.9776 - val_loss: 0.2149 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.1830 - accuracy: 0.9801 - val_loss: 0.2147 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.1883 - accuracy: 0.9776 - val_loss: 0.2144 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.1743 - accuracy: 0.9827 - val_loss: 0.2142 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.1990 - accuracy: 0.9724 - val_loss: 0.2140 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.1876 - accuracy: 0.9776 - val_loss: 0.2138 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.1751 - accuracy: 0.9821 - val_loss: 0.2136 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.1882 - accuracy: 0.9745 - val_loss: 0.2134 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1736 - accuracy: 0.9801 - val_loss: 0.2132 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 295ms/step - loss: 0.1899 - accuracy: 0.9776 - val_loss: 0.2130 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.1800 - accuracy: 0.9791 - val_loss: 0.2128 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.1894 - accuracy: 0.9791 - val_loss: 0.2126 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.1790 - accuracy: 0.9770 - val_loss: 0.2125 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1865 - accuracy: 0.9796 - val_loss: 0.2123 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.1860 - accuracy: 0.9796 - val_loss: 0.2121 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.1886 - accuracy: 0.9770 - val_loss: 0.2119 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.1859 - accuracy: 0.9811 - val_loss: 0.2117 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.1857 - accuracy: 0.9796 - val_loss: 0.2115 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.1955 - accuracy: 0.9745 - val_loss: 0.2114 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.1843 - accuracy: 0.9750 - val_loss: 0.2112 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.1845 - accuracy: 0.9786 - val_loss: 0.2111 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 0.1960 - accuracy: 0.9709 - val_loss: 0.2109 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 0.1795 - accuracy: 0.9786 - val_loss: 0.2108 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.1900 - accuracy: 0.9735 - val_loss: 0.2106 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.1729 - accuracy: 0.9827 - val_loss: 0.2104 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.1865 - accuracy: 0.9765 - val_loss: 0.2102 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 0.1842 - accuracy: 0.9781 - val_loss: 0.2101 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.1886 - accuracy: 0.9735 - val_loss: 0.2100 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.1846 - accuracy: 0.9791 - val_loss: 0.2098 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.1907 - accuracy: 0.9791 - val_loss: 0.2097 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 0.1988 - accuracy: 0.9755 - val_loss: 0.2096 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.1811 - accuracy: 0.9770 - val_loss: 0.2095 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.1907 - accuracy: 0.9740 - val_loss: 0.2094 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.1798 - accuracy: 0.9801 - val_loss: 0.2093 - val_accuracy: 0.9381 - lr: 5.0000e-06\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.1845 - accuracy: 0.9750 - val_loss: 0.2092 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 0.1812 - accuracy: 0.9765 - val_loss: 0.2091 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.1786 - accuracy: 0.9816 - val_loss: 0.2089 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.1877 - accuracy: 0.9745 - val_loss: 0.2088 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.1782 - accuracy: 0.9760 - val_loss: 0.2087 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.1875 - accuracy: 0.9776 - val_loss: 0.2085 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1792 - accuracy: 0.9806 - val_loss: 0.2084 - val_accuracy: 0.9393 - lr: 5.0000e-06\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.1870 - accuracy: 0.9776 - val_loss: 0.2082 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.1884 - accuracy: 0.9806 - val_loss: 0.2081 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 0.1841 - accuracy: 0.9801 - val_loss: 0.2079 - val_accuracy: 0.9405 - lr: 5.0000e-06\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 0.1842 - accuracy: 0.9760 - val_loss: 0.2078 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.1758 - accuracy: 0.9801 - val_loss: 0.2077 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.1848 - accuracy: 0.9776 - val_loss: 0.2076 - val_accuracy: 0.9417 - lr: 5.0000e-06\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.1826 - accuracy: 0.9801 - val_loss: 0.2075 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.1817 - accuracy: 0.9776 - val_loss: 0.2074 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 0.1783 - accuracy: 0.9776 - val_loss: 0.2073 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.1871 - accuracy: 0.9760 - val_loss: 0.2072 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1817 - accuracy: 0.9735 - val_loss: 0.2071 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.1875 - accuracy: 0.9781 - val_loss: 0.2071 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.1883 - accuracy: 0.9770 - val_loss: 0.2071 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.1830 - accuracy: 0.9801 - val_loss: 0.2070 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.1794 - accuracy: 0.9811 - val_loss: 0.2068 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1766 - accuracy: 0.9821 - val_loss: 0.2067 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.1706 - accuracy: 0.9791 - val_loss: 0.2066 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.1936 - accuracy: 0.9745 - val_loss: 0.2064 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 352ms/step - loss: 0.1888 - accuracy: 0.9719 - val_loss: 0.2063 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.1868 - accuracy: 0.9740 - val_loss: 0.2062 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.1751 - accuracy: 0.9791 - val_loss: 0.2061 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.1866 - accuracy: 0.9745 - val_loss: 0.2060 - val_accuracy: 0.9429 - lr: 5.0000e-06\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.1986 - accuracy: 0.9755 - val_loss: 0.2060 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.1857 - accuracy: 0.9781 - val_loss: 0.2059 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 0.1915 - accuracy: 0.9735 - val_loss: 0.2059 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.1754 - accuracy: 0.9806 - val_loss: 0.2058 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.1720 - accuracy: 0.9811 - val_loss: 0.2058 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 298ms/step - loss: 0.1825 - accuracy: 0.9740 - val_loss: 0.2057 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.1915 - accuracy: 0.9750 - val_loss: 0.2056 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.1860 - accuracy: 0.9796 - val_loss: 0.2056 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.1895 - accuracy: 0.9750 - val_loss: 0.2055 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.1799 - accuracy: 0.9806 - val_loss: 0.2055 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.1781 - accuracy: 0.9801 - val_loss: 0.2055 - val_accuracy: 0.9440 - lr: 5.0000e-06\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.1830 - accuracy: 0.9791 - val_loss: 0.2054 - val_accuracy: 0.9452 - lr: 5.0000e-06\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.1829 - accuracy: 0.9755 - val_loss: 0.2054 - val_accuracy: 0.9452 - lr: 5.0000e-06\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 0.1763 - accuracy: 0.9796 - val_loss: 0.2053 - val_accuracy: 0.9452 - lr: 5.0000e-06\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.1817 - accuracy: 0.9786 - val_loss: 0.2052 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 291ms/step - loss: 0.1901 - accuracy: 0.9740 - val_loss: 0.2051 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.1846 - accuracy: 0.9821 - val_loss: 0.2050 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.1834 - accuracy: 0.9755 - val_loss: 0.2049 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1826 - accuracy: 0.9781 - val_loss: 0.2048 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 0.1891 - accuracy: 0.9765 - val_loss: 0.2047 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 0.1792 - accuracy: 0.9776 - val_loss: 0.2046 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 0.1832 - accuracy: 0.9770 - val_loss: 0.2046 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 0.1904 - accuracy: 0.9755 - val_loss: 0.2045 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.1742 - accuracy: 0.9827 - val_loss: 0.2044 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 0.1828 - accuracy: 0.9770 - val_loss: 0.2043 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1911 - accuracy: 0.9750 - val_loss: 0.2042 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.1700 - accuracy: 0.9837 - val_loss: 0.2042 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 0.1719 - accuracy: 0.9806 - val_loss: 0.2041 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 314ms/step - loss: 0.1807 - accuracy: 0.9755 - val_loss: 0.2040 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.1824 - accuracy: 0.9821 - val_loss: 0.2040 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 0.1840 - accuracy: 0.9770 - val_loss: 0.2039 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 0.1784 - accuracy: 0.9776 - val_loss: 0.2039 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.1763 - accuracy: 0.9801 - val_loss: 0.2038 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.1794 - accuracy: 0.9827 - val_loss: 0.2038 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.1745 - accuracy: 0.9786 - val_loss: 0.2038 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.1751 - accuracy: 0.9832 - val_loss: 0.2037 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.1771 - accuracy: 0.9811 - val_loss: 0.2037 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.1784 - accuracy: 0.9770 - val_loss: 0.2037 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.1650 - accuracy: 0.9832 - val_loss: 0.2036 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.1740 - accuracy: 0.9821 - val_loss: 0.2036 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.1826 - accuracy: 0.9806 - val_loss: 0.2037 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 0.1812 - accuracy: 0.9786 - val_loss: 0.2036 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.1897 - accuracy: 0.9745 - val_loss: 0.2036 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 380ms/step - loss: 0.1888 - accuracy: 0.9781 - val_loss: 0.2037 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.1785 - accuracy: 0.9801 - val_loss: 0.2037 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.1770 - accuracy: 0.9801 - val_loss: 0.2036 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.1753 - accuracy: 0.9796 - val_loss: 0.2036 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 0.1774 - accuracy: 0.9827 - val_loss: 0.2035 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.1755 - accuracy: 0.9796 - val_loss: 0.2034 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 0.1831 - accuracy: 0.9801 - val_loss: 0.2033 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.1736 - accuracy: 0.9832 - val_loss: 0.2032 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 0.1870 - accuracy: 0.9776 - val_loss: 0.2031 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.1864 - accuracy: 0.9770 - val_loss: 0.2031 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.1744 - accuracy: 0.9816 - val_loss: 0.2031 - val_accuracy: 0.9464 - lr: 5.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqh2oDD4ixIS"
      },
      "source": [
        "6.Plotting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tx0Txay0v5-",
        "outputId": "f495f92f-90a8-4fb1-cacd-4429d723ba1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_K4G9CuTA4d",
        "outputId": "98af015f-421b-4d49-ec0c-ebac1f633609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "Y_pred = DD_Net.predict([X_test_0,X_test_1, D_test,A_test])\n",
        "labels = ['Grab', 'Tap', 'Expand', 'Pinch', 'RC', 'RCC', 'SR', 'SL', 'SU', 'SD', 'SX', 'S+', 'SV', 'Shake']\n",
        "\n",
        "y_true = []\n",
        "for i in np.argmax(Y_test,axis=1):\n",
        "    y_true.append(labels[i])\n",
        "\n",
        "y_pred = []\n",
        "for i in np.argmax(Y_pred,axis=1):\n",
        "    y_pred.append(labels[i])\n",
        "\n",
        "cm_analysis(y_true,y_pred, 'SHREC_14.png', labels, ymap=None, figsize=(8,8))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vgdfXB509Lyi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
